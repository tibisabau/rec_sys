{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d74f92-57dd-49d5-8e6d-b5ab8c7ee75c",
   "metadata": {},
   "source": [
    "# DSAIT4335 Recommender Systems\n",
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18281d7-d2fc-4a67-9bc9-21d25bad6cfc",
   "metadata": {},
   "source": [
    "In this project, you will work to build different recommendation models and evaluate the effectiveness of these models through offline experiments. The dataset used for the experiments is **MovieLens100K**, a movie recommendation dataset collected by GroupLens: https://grouplens.org/datasets/movielens/100k/. For more details, check the project description on Brightspace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cbc07f-b579-4f9b-85b5-dc43c2d7ce48",
   "metadata": {},
   "source": [
    "# Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944993d6-8983-46cf-880f-753f65975811",
   "metadata": {},
   "source": [
    "The MovieLens100K is already splitted into 80% training and 20% test sets. Along with training and test sets, movies metadata as content information is also provided.\n",
    "\n",
    "**Expected file structure** for this assignment:   \n",
    "   \n",
    "   ```\n",
    "   RecSysProject/\n",
    "   ├── training.txt\n",
    "   ├── test.txt\n",
    "   ├── movies.txt\n",
    "   └── codes.ipynb\n",
    "   ```\n",
    "\n",
    "**Note:** Be sure to run all cells in each section sequentially, so that intermediate variables and packages are properly carried over to subsequent cells.\n",
    "\n",
    "**Note** Be sure to run all cells such that the submitted file contains the output of each cell.\n",
    "\n",
    "**Note** Feel free to add cells if you need more for answering a question.\n",
    "\n",
    "**Submission:** Answer all the questions in this jupyter-notebook file. Submit this jupyter-notebook file (your answers included) to Brightspace. Change the name of this jupyter-notebook file to your group number: example, group10 -> 10.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977945fa-a202-49c4-a41d-12ada7b437da",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "302a2b5b-fdf1-41c8-b6a6-bc1cd453425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\kevin\\anaconda3\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in c:\\users\\kevin\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch  \n",
    "\n",
    "# you can refer https://huggingface.co/docs/transformers/en/model_doc/bert for various versions of the pre-trained model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e3b0e3c-74d9-436b-b676-56bc2a8528a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the status of BERT installation:\n",
      "BERT libraries loaded successfully!\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# For BERT embeddings (install: pip install transformers torch)\n",
    "print(\"Check the status of BERT installation:\")\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    import torch\n",
    "    BERT_AVAILABLE = True\n",
    "    print(\"BERT libraries loaded successfully!\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "except ImportError:\n",
    "    BERT_AVAILABLE = False\n",
    "    print(\"BERT libraries not available. Install with: pip install transformers torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8055513b-9f14-4d18-b32a-7c2ee386e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine, correlation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "import re\n",
    "import time, math\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd1eff-8e8b-4f65-b92a-778107a256cc",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d220e9dc-3a45-4d25-b214-23d6555cb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1        1       5\n",
       "1        1        2       3\n",
       "2        1        3       4\n",
       "3        1        4       3\n",
       "4        1        5       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data: (80000, 4)\n",
      "--------------------------------\n",
      "The test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1        6       5\n",
       "1        1       10       3\n",
       "2        1       12       5\n",
       "3        1       14       5\n",
       "4        1       17       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the test data: (20000, 4)\n"
     ]
    }
   ],
   "source": [
    "# loading the training set and test set\n",
    "columns_name=['user_id','item_id','rating','timestamp']\n",
    "train_data = pd.read_csv('training.txt', sep='\\t', names=columns_name)\n",
    "test_data = pd.read_csv('test.txt', sep='\\t', names=columns_name)\n",
    "\n",
    "print(f'The training data:')\n",
    "display(train_data[['user_id','item_id','rating']].head())\n",
    "print(f'The shape of the training data: {train_data.shape}')\n",
    "print('--------------------------------')\n",
    "print(f'The test data:')\n",
    "display(test_data[['user_id','item_id','rating']].head())\n",
    "print(f'The shape of the test data: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e84160d-ef0e-4e58-8ace-307fb8cd5a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation, Children's, Comedy</td>\n",
       "      <td>A group of sentient toys, who pretend to be li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action, Adventure, Thriller</td>\n",
       "      <td>In 1986, MI6 agents James Bond and Alec Trevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>On New Year's Eve, bellhop Sam (Marc Lawrence)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>Action, Comedy, Drama</td>\n",
       "      <td>Chili Palmer is a Miami-based loan shark and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>After giving a guest lecture on criminal psych...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title                         genres  \\\n",
       "0        1   Toy Story (1995)  Animation, Children's, Comedy   \n",
       "1        2   GoldenEye (1995)    Action, Adventure, Thriller   \n",
       "2        3  Four Rooms (1995)                       Thriller   \n",
       "3        4  Get Shorty (1995)          Action, Comedy, Drama   \n",
       "4        5     Copycat (1995)         Crime, Drama, Thriller   \n",
       "\n",
       "                                         description  \n",
       "0  A group of sentient toys, who pretend to be li...  \n",
       "1  In 1986, MI6 agents James Bond and Alec Trevel...  \n",
       "2  On New Year's Eve, bellhop Sam (Marc Lawrence)...  \n",
       "3  Chili Palmer is a Miami-based loan shark and m...  \n",
       "4  After giving a guest lecture on criminal psych...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('movies.txt',names=['item_id','title','genres','description'],sep='\\t')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d50b57f-b07a-49b0-ad8c-31566a355cc7",
   "metadata": {},
   "source": [
    "# Task 1) Implementation of different recommendation models as well as a hybrid model combining those recommendation models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2f3d7",
   "metadata": {},
   "source": [
    "### A. Content Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5dadd",
   "metadata": {},
   "source": [
    "#### A.1 Deriving Content Representation with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f55e25ab-353d-4a7c-bf68-9deb201bfbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_embeddings(content):\n",
    "    \"\"\"\n",
    "    Generate BERT embeddings for movie content.\n",
    "\n",
    "    Args:\n",
    "        content: Content of items\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: BERT embeddings matrix\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE:\n",
    "        print(\"BERT libraries not available. Install with: pip install transformers torch\")\n",
    "        return None\n",
    "\n",
    "    if content is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(content, pd.Series):\n",
    "        content = content.fillna(\"\").astype(str).tolist()\n",
    "    elif isinstance(content, np.ndarray):\n",
    "        content = content.astype(str).tolist()\n",
    "\n",
    "    model_name = 'distilbert-base-uncased'\n",
    "\n",
    "    print(f\"Loading BERT model: {model_name}\")\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    # Set device (GPU if available)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using cuda or cpu: {device}\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Generate embeddings in batches\n",
    "    batch_size = 32  # Adjust based on available memory\n",
    "    emb = []\n",
    "\n",
    "    for i in range(0, len(content), batch_size):\n",
    "        if i % (batch_size * 10) == 0:\n",
    "            print(f\"Processing batch {i//batch_size + 1}/{len(content)//batch_size + 1}\")\n",
    "\n",
    "        batch_texts = content[i:i + batch_size]\n",
    "\n",
    "        # Tokenize batch\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Move to device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            # Use [CLS] token embedding (first token)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            emb.extend(batch_embeddings)\n",
    "\n",
    "    emb = np.array(emb)\n",
    "\n",
    "    print(f\"BERT embeddings generated: {emb.shape}\")\n",
    "    print(f\"Embedding dimension: {emb.shape[1]}\")\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad8246",
   "metadata": {},
   "source": [
    "#### A.2 Deriving the representation of items for three types of content: \n",
    "- title + genres \n",
    "- description \n",
    "- title + genres + description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25db7c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model: distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda or cpu: cpu\n",
      "Using device: cpu\n",
      "Processing batch 1/53\n",
      "Processing batch 11/53\n",
      "Processing batch 21/53\n",
      "Processing batch 31/53\n",
      "Processing batch 41/53\n",
      "Processing batch 51/53\n",
      "BERT embeddings generated: (1682, 768)\n",
      "Embedding dimension: 768\n",
      "Loading BERT model: distilbert-base-uncased\n",
      "Using cuda or cpu: cpu\n",
      "Using device: cpu\n",
      "Processing batch 1/53\n",
      "Processing batch 11/53\n",
      "Processing batch 21/53\n",
      "Processing batch 31/53\n",
      "Processing batch 41/53\n",
      "Processing batch 51/53\n",
      "BERT embeddings generated: (1682, 768)\n",
      "Embedding dimension: 768\n",
      "Loading BERT model: distilbert-base-uncased\n",
      "Using cuda or cpu: cpu\n",
      "Using device: cpu\n",
      "Processing batch 1/53\n",
      "Processing batch 11/53\n",
      "Processing batch 21/53\n",
      "Processing batch 31/53\n",
      "Processing batch 41/53\n",
      "Processing batch 51/53\n",
      "BERT embeddings generated: (1682, 768)\n",
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Implement code to derive the content representation for title and genres. Concatenate the two content as: title + ' ' + genres\n",
    "item_emb_titlegenres = None\n",
    "############# Your code here ############\n",
    "title_genres_text = (movies['title'].astype(str) + ' ' + movies['genres'].astype(str)).tolist()\n",
    "item_emb_titlegenres = create_bert_embeddings(title_genres_text)\n",
    "#########################################\n",
    "\n",
    "# Implement code to derive the content representation for description.\n",
    "item_emb_description = None\n",
    "############# Your code here ############\n",
    "description_text = movies['description'].fillna(\"\").astype(str).tolist()\n",
    "item_emb_description = create_bert_embeddings(description_text)\n",
    "#########################################\n",
    "\n",
    "# Implement code to derive the content representation for title, genres, and description. Concatenate the two content as: title + ' ' + genres + '' + description\n",
    "item_emb_full = None\n",
    "############# Your code here ############\n",
    "full_text = (movies['title'].astype(str) + ' ' + \n",
    "             movies['genres'].astype(str) + ' ' + \n",
    "             movies['description'].fillna(\"\").astype(str)).tolist()\n",
    "item_emb_full = create_bert_embeddings(full_text)\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07da03b",
   "metadata": {},
   "source": [
    "#### A.3 Get Item Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38e402f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_emb(item_id, content_type):\n",
    "    # Implement the function that given content type (title+genres, description, or title+genres+description) returns the embedding derived for the corresponding item_id. \n",
    "    # Hint1: keep in mind that item_id in the data starts from 1, but in the embedding variable it starts from 0, e.g., item_id 100 corresponds to index 99 in embedding variable..\n",
    "    # Hint2: use if-else conditions to return the embedding for the requested content types.\n",
    "    # Hint3: use the global variables (embeddings) already computed in previous cells.\n",
    "\n",
    "    emb = None\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    idx = int(item_id) - 1\n",
    "    if content_type == 'title_genres':\n",
    "        emb = item_emb_titlegenres[idx]\n",
    "    elif content_type == 'description':\n",
    "        emb = item_emb_description[idx]\n",
    "    else:\n",
    "        emb = item_emb_full[idx]\n",
    "    #########################################\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca727f",
   "metadata": {},
   "source": [
    "#### A.4 User Profile Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b143580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interacted_items_embs_rating(train_data, user_id, content_type):\n",
    "    # Implement the function that given content type (title+genres, description, or title+genres+description) returns the embeddings and ratings of interacted items by user_id=100. \n",
    "    # Hint1: use train_data to retrieve the item_ids that target user (user_id=100 in this example) interacted, then pass these item_ids to function previously implemented to retrieve the embeddings and ratings.\n",
    "\n",
    "    embs, ratings = [], []\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    user_interactions = train_data[train_data['user_id'] == user_id]\n",
    "\n",
    "    for _, row in user_interactions.iterrows():\n",
    "        item_id = row['item_id']\n",
    "        rating = row['rating']\n",
    "        \n",
    "        # Get embedding for this item\n",
    "        emb = get_item_emb(item_id, content_type)\n",
    "        \n",
    "        if emb is not None:\n",
    "            embs.append(emb)\n",
    "            ratings.append(rating)\n",
    "    #########################################\n",
    "\n",
    "    return embs, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca90889",
   "metadata": {},
   "source": [
    "#### A.5 Deriving the representation for a user using the following aggregation methods:\n",
    "1. **avg:** Average representation of interacted item \n",
    "2. **weighted_avg:** Weighted average representation of interacted item using rating values\n",
    "3. **avg_pos:** Average representation of positively interacted item (ratings >= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fed87724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_emb(train_data, user_id, content_type, aggregation_method):\n",
    "    # Implement the function that given content type (title+genres, description, or title+genres+description) and aggregation method (avg, weighted_avg, avg_pos) returns the representation of a user. \n",
    "    # Hint1: use the previsouly implemented items for retrieving ratings and representation of interacted items by a user.\n",
    "\n",
    "    emb = []\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    embs, ratings = get_interacted_items_embs_rating(train_data, user_id, content_type)\n",
    "\n",
    "    embs = np.array(embs)\n",
    "    ratings = np.array(ratings)\n",
    "\n",
    "    if aggregation_method == 'avg':\n",
    "        emb = np.mean(embs, axis=0)\n",
    "\n",
    "    elif aggregation_method == 'weighted_avg':\n",
    "        weights = ratings / ratings.sum()\n",
    "        emb = np.average(embs, axis=0, weights=weights)\n",
    "\n",
    "    else: \n",
    "        mask = ratings >= 4\n",
    "        if mask.sum() == 0:\n",
    "            return None  \n",
    "        emb = np.mean(embs[mask], axis=0)\n",
    "    #########################################\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3ad12",
   "metadata": {},
   "source": [
    "#### A.6 Predict Score for User-Item Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25a120c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score for user_id=100 and item_id=266 for content type full and aggregation method avg:\n",
      "142.68704223632812\n"
     ]
    }
   ],
   "source": [
    "def get_user_item_prediction(train_data, user_id, item_id, content_type, aggregation_method):\n",
    "    # Implement the function that given content type and aggregation method returns the predicted rating for a user-item pair. \n",
    "    # Hint1: use the previsouly implemented functions for retrieving the embeddings and then compute the dot product of user and item embeddings.\n",
    "\n",
    "    pred_rating = 0.0\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    user_emb = get_user_emb(train_data, user_id, content_type, aggregation_method)\n",
    "    item_emb = get_item_emb(item_id, content_type)    \n",
    "    pred_rating = float(np.dot(user_emb, item_emb))\n",
    "    #########################################\n",
    "\n",
    "    return pred_rating\n",
    "    \n",
    "user_id, item_id = 100, 266\n",
    "content_type, aggregation_method = 'full', 'avg' # alternatives are content_type={title_genres,description,full} and aggregation_method={avg,weighted_avg,avg_pos}\n",
    "print('Predicted score for user_id=100 and item_id=266 for content type '+content_type+' and aggregation method '+aggregation_method+':')\n",
    "print(get_user_item_prediction(train_data, user_id, item_id, content_type, aggregation_method))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a42786",
   "metadata": {},
   "source": [
    "### B. User-based neighborhood method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060b210",
   "metadata": {},
   "source": [
    "#### B.1 Implementing a function that computes the Pearson Correlation between two users. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa01a3",
   "metadata": {},
   "source": [
    "The **Pearson correlation coefficient** between two users \\(x\\) and \\(y\\) is defined as:\n",
    "\n",
    "$$\n",
    "r_{xy} = \\frac{\\sum_{i \\in I_{xy}} (x_i - \\bar{x})(y_i - \\bar{y})}\n",
    "              {\\sqrt{\\sum_{i \\in I_{xy}} (x_i - \\bar{x})^2} \\cdot \\sqrt{\\sum_{i \\in I_{xy}} (y_i - \\bar{y})^2}}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $I_{xy}$ = set of items rated by both users  \n",
    "- $x_i$, $y_i$ = ratings of users \\(x\\) and \\(y\\) on item \\(i\\)  \n",
    "- $\\bar{x}$, $\\bar{y}$ = mean ratings of users \\(x\\) and \\(y\\) on the common items  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7105c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between users 1 and 2 is 0.2697\n"
     ]
    }
   ],
   "source": [
    "def pearson_correlation(user1_ratings: pd.Series, user2_ratings: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Compute Pearson correlation coefficient between two users' rating vectors.\n",
    "    \n",
    "    user1_ratings, user2_ratings: Pandas Series indexed by item IDs. They may contain NaN for unrated items.\n",
    "    Returns: float (correlation between -1 and 1). Returns 0 if not enough data.\n",
    "    \"\"\"\n",
    "    # Find the common items both users have rated\n",
    "    common_items = user1_ratings.index.intersection(user2_ratings.index)\n",
    "    \n",
    "    if len(common_items) < 2:\n",
    "        # Not enough common ratings to compute correlation\n",
    "        return 0.0\n",
    "\n",
    "    # Extract the ratings for the common items\n",
    "    u1 = user1_ratings.loc[common_items]\n",
    "    u2 = user2_ratings.loc[common_items]\n",
    "\n",
    "    # Drop any NaNs just in case\n",
    "    valid = u1.notna() & u2.notna()\n",
    "    u1 = u1[valid]\n",
    "    u2 = u2[valid]\n",
    "\n",
    "    if len(u1) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute mean-centered ratings\n",
    "    u1_mean = u1.mean()\n",
    "    u2_mean = u2.mean()\n",
    "\n",
    "    numerator = ((u1 - u1_mean) * (u2 - u2_mean)).sum()\n",
    "    denominator = ((u1 - u1_mean).pow(2).sum() ** 0.5) * ((u2 - u2_mean).pow(2).sum() ** 0.5)\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "\n",
    "    result = numerator / denominator\n",
    "    return result\n",
    "\n",
    "user1, user2 = 1, 2\n",
    "user1_ratings = train_data[train_data['user_id'] == user1].set_index('item_id')['rating']\n",
    "user2_ratings = train_data[train_data['user_id'] == user2].set_index('item_id')['rating']\n",
    "print(f\"Pearson Correlation between users {user1} and {user2} is {pearson_correlation(user1_ratings, user2_ratings):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92aaa0",
   "metadata": {},
   "source": [
    "#### B.2 User Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e7d26be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix creation started! This may take around 5-10 minutes...\n",
      "Running time: 460.0330 seconds\n"
     ]
    }
   ],
   "source": [
    "def compute_user_similarity_matrix(train_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute user-user similarity matrix using Pearson correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame with columns ['user_id', 'item_id', 'rating']\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: user-user similarity matrix (rows & cols = user_ids)\n",
    "    \"\"\"\n",
    "    users = train_data['user_id'].unique()\n",
    "    user_similarity_matrix = pd.DataFrame(np.zeros((len(users), len(users))), index=users, columns=users)\n",
    "    \n",
    "    # Create a user-item rating pivot for faster lookups\n",
    "    user_ratings = {user: train_data[train_data['user_id'] == user].set_index('item_id')['rating']\n",
    "                    for user in users}\n",
    "    \n",
    "    # Compute pairwise Pearson correlations\n",
    "    for i, user1 in enumerate(users):\n",
    "        for j, user2 in enumerate(users):\n",
    "            if i > j:  # Use symmetry to avoid redundant computation\n",
    "                user_similarity_matrix.loc[user1, user2] = user_similarity_matrix.loc[user2, user1]\n",
    "                continue\n",
    "            if user1 == user2:\n",
    "                user_similarity_matrix.loc[user1, user2] = 1.0\n",
    "                continue\n",
    "            \n",
    "            sim = pearson_correlation(user_ratings[user1], user_ratings[user2])\n",
    "            user_similarity_matrix.loc[user1, user2] = sim\n",
    "            user_similarity_matrix.loc[user2, user1] = sim  # symmetric matrix\n",
    "    \n",
    "    return user_similarity_matrix\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'Similarity matrix creation started! This may take around 5-10 minutes...')\n",
    "user_similarity_matrix = compute_user_similarity_matrix(train_data)  \n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234988be",
   "metadata": {},
   "source": [
    "#### B.3 Implementing a function that returns k most similar users along with the similarity values to a target user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bc43616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of user 1 are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(656, 1.0000000000000002),\n",
       " (289, 1.0000000000000002),\n",
       " (29, 1.0000000000000002),\n",
       " (926, 1.0000000000000002),\n",
       " (46, 1.0000000000000002),\n",
       " (920, 1.0000000000000002),\n",
       " (485, 1.0),\n",
       " (61, 1.0),\n",
       " (824, 1.0),\n",
       " (408, 1.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_k_user_neighbors(user_similarity_matrix: pd.DataFrame, target_user, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar users to the target user.\n",
    "\n",
    "    Parameters:\n",
    "    - user_similarity_matrix: pd.DataFrame, user-user similarity values (indexed by user IDs)\n",
    "    - target_user: user ID for whom we want neighbors\n",
    "    - k: number of neighbors to retrieve\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(neighbor_user_id, similarity), ...] sorted by similarity descending\n",
    "    \"\"\"\n",
    "    if target_user not in user_similarity_matrix.index:\n",
    "        return []\n",
    "\n",
    "    # Extract similarity scores for the target user\n",
    "    user_similarities = user_similarity_matrix.loc[target_user]\n",
    "\n",
    "    # Drop self-similarity (user with themselves)\n",
    "    user_similarities = user_similarities.drop(target_user, errors='ignore')\n",
    "\n",
    "    # Sort users by similarity (descending order)\n",
    "    sorted_neighbors = user_similarities.sort_values(ascending=False)\n",
    "\n",
    "    # Select top-k most similar users\n",
    "    top_k = sorted_neighbors.head(k)\n",
    "\n",
    "    # Convert to list of tuples\n",
    "    top_k_neighbors = list(zip(top_k.index, top_k.values))\n",
    "\n",
    "    return top_k_neighbors\n",
    "\n",
    "target_user, k = 1, 10\n",
    "print(f\"Neighbors of user {target_user} are:\")\n",
    "get_k_user_neighbors(user_similarity_matrix, target_user, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ee23c",
   "metadata": {},
   "source": [
    "#### B.4 Implementing a function that predicts the rating for a target user might give to a target item using user-user similarity matrix and the following equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf09cb5",
   "metadata": {},
   "source": [
    "The **predicted rating** for a target user \\(u\\) on item \\(i\\) using mean-centered user-based collaborative filtering is:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = \\bar{r}_u + \\frac{\\sum_{v \\in N(u)} s(u,v) \\cdot (r_{v,i} - \\bar{r}_v)}\n",
    "                             {\\sum_{v \\in N(u)} |s(u,v)|}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\hat{r}_{u,i}$ = predicted rating for user \\(u\\) on item \\(i\\)  \n",
    "- $\\bar{r}_u$ = mean rating of the target user \\(u\\)  \n",
    "- $N(u)$ = set of top-\\(k\\) neighbors of user \\(u\\) who have rated item \\(i\\)  \n",
    "- $s(u,v)$ = similarity between users \\(u\\) and \\(v\\)  \n",
    "- $r_{v,i}$ = rating of neighbor \\(v\\) on item \\(i\\)  \n",
    "- $\\bar{r}_v$ = mean rating of neighbor \\(v\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbca8f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual rating for user 1 and item 17 is 3. The predicted rating by user-based CF for user 1 and item 17 is 3.4832\n"
     ]
    }
   ],
   "source": [
    "def predict_rating_user_based(train_data: pd.DataFrame, user_similarity_matrix: pd.DataFrame, target_user, target_item, k=5):\n",
    "    \"\"\"\n",
    "    Predict rating for target_user and target_item using mean-centered user-based CF.\n",
    "\n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame with columns ['user_id', 'item_id', 'rating']\n",
    "    - user_similarity_matrix: pd.DataFrame of user-user similarities\n",
    "    - target_user: user ID\n",
    "    - target_item: item ID\n",
    "    - k: number of neighbors to consider\n",
    "\n",
    "    Returns:\n",
    "    - float: predicted rating, or np.nan if not possible\n",
    "    \"\"\"\n",
    "    # Check if target_user and target_item exist in data\n",
    "    if target_user not in user_similarity_matrix.index:\n",
    "        return np.nan\n",
    "    if target_item not in train_data['item_id'].unique():\n",
    "        return np.nan\n",
    "\n",
    "    # Get mean rating of the target user\n",
    "    target_user_ratings = train_data[train_data['user_id'] == target_user]['rating']\n",
    "    if target_user_ratings.empty:\n",
    "        return np.nan\n",
    "    target_user_mean = target_user_ratings.mean()\n",
    "\n",
    "    # Get all users who rated the target item\n",
    "    item_raters = train_data[train_data['item_id'] == target_item]\n",
    "    if item_raters.empty:\n",
    "        return np.nan\n",
    "\n",
    "    # Get similarities between target_user and those raters\n",
    "    similarities = user_similarity_matrix.loc[target_user, item_raters['user_id']]\n",
    "    \n",
    "    # Combine raters' data and similarity\n",
    "    item_raters = item_raters.copy()\n",
    "    item_raters['similarity'] = similarities.values\n",
    "\n",
    "    # Keep only top-k most similar users\n",
    "    item_raters = item_raters.sort_values(by='similarity', ascending=False).head(k)\n",
    "\n",
    "    # Remove users with non-positive similarity (optional but common)\n",
    "    item_raters = item_raters[item_raters['similarity'] > 0]\n",
    "\n",
    "    if item_raters.empty:\n",
    "        return np.nan\n",
    "\n",
    "    # Compute mean rating for each neighbor\n",
    "    neighbor_means = (\n",
    "        train_data.groupby('user_id')['rating']\n",
    "        .mean()\n",
    "        .reindex(item_raters['user_id'])\n",
    "    )\n",
    "\n",
    "    # Mean-centered ratings: (r_ui - mean_u)\n",
    "    item_raters['mean_centered'] = item_raters['rating'] - neighbor_means.values\n",
    "\n",
    "    numerator = (item_raters['similarity'] * item_raters['mean_centered']).sum()\n",
    "    denominator = item_raters['similarity'].abs().sum()\n",
    "\n",
    "    if denominator == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predicted rating using mean-centering\n",
    "    predicted_rating = target_user_mean + numerator / denominator\n",
    "    \n",
    "    # Clamp to valid rating scale\n",
    "    return predicted_rating\n",
    "\n",
    "target_user, target_item, k = 1, 17, 50\n",
    "print(f\"The actual rating for user {target_user} and item {target_item} is 3. The predicted rating by user-based CF for user {target_user} and item {target_item} is {predict_rating_user_based(train_data, user_similarity_matrix, target_user, target_item, k):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458adf7",
   "metadata": {},
   "source": [
    "#### B.5 Implementing a function that generates top-K recommendation list for a target user using user-based CF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d067eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 recommendations for user 1:\n",
      "Item 851: 5.4403\n",
      "Item 1368: 5.2213\n",
      "Item 1467: 5.1903\n",
      "Item 1599: 5.1101\n",
      "Item 1293: 4.9567\n",
      "Item 1449: 4.9468\n",
      "Item 1639: 4.9344\n",
      "Item 1642: 4.9321\n",
      "Item 1500: 4.8958\n",
      "Item 1131: 4.8634\n",
      "Running time: 9.4114 seconds\n"
     ]
    }
   ],
   "source": [
    "def recommend_topk_user_based(train_data, user_similarity_matrix, target_user, k=5):\n",
    "    \"\"\"\n",
    "    Generate Top-K recommendations for a target user using User-based CF.\n",
    "    \n",
    "    Args:\n",
    "        train_data (pd.DataFrame): ratings data with columns [user_id, item_id, rating]\n",
    "        user_similarity_matrix (pd.DataFrame): precomputed user-user similarity matrix\n",
    "        target_user (int): user_id of the target user\n",
    "        k (int): number of most similar neighbors to consider\n",
    "    \n",
    "    Returns:\n",
    "        list of (item_id, predicted_score) sorted by score desc\n",
    "    \"\"\"\n",
    "    # Check if target_user exists\n",
    "    if target_user not in user_similarity_matrix.index:\n",
    "        return []\n",
    "\n",
    "    # Get items already rated by target_user\n",
    "    user_rated_items = set(train_data[train_data['user_id'] == target_user]['item_id'])\n",
    "\n",
    "    # Get all unique items\n",
    "    all_items = train_data['item_id'].unique()\n",
    "\n",
    "    # Items not yet rated by the user\n",
    "    candidate_items = [item for item in all_items if item not in user_rated_items]\n",
    "    \n",
    "    # Predict ratings for each candidate item\n",
    "    predictions = []\n",
    "    for item in candidate_items:\n",
    "        pred = predict_rating_user_based(train_data, user_similarity_matrix, target_user, item, k)\n",
    "        if not np.isnan(pred):\n",
    "            predictions.append((item, pred))\n",
    "\n",
    "    # Sort predictions by predicted rating (descending)\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top-10 (or fewer if fewer available)\n",
    "    result = predictions[:10]\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "target_user, k = 1, 30\n",
    "recommendations = recommend_topk_user_based(train_data, user_similarity_matrix, target_user, k)\n",
    "print(f\"Top-10 recommendations for user {target_user}:\")\n",
    "for item, score in recommendations:\n",
    "    print(f\"Item {item}: {score:.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e4d8a",
   "metadata": {},
   "source": [
    "### C. Item-based neighborhood method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0421aa",
   "metadata": {},
   "source": [
    "#### C.1 Implementing a function that computes the Cosine similarity between two items. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d443b63",
   "metadata": {},
   "source": [
    "The **cosine similarity** between two items \\(i\\) and \\(j\\) is defined as:\n",
    "\n",
    "$$\n",
    "\\text{sim}(i,j) = \\frac{\\sum_{u \\in U_{ij}} r_{u,i} \\cdot r_{u,j}}\n",
    "                      {\\sqrt{\\sum_{u \\in U_{ij}} r_{u,i}^2} \\cdot \\sqrt{\\sum_{u \\in U_{ij}} r_{u,j}^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\(r_{u,i}\\) = rating of user \\(u\\) on item \\(i\\)  \n",
    "- \\(r_{u,j}\\) = rating of user \\(u\\) on item \\(j\\)  \n",
    "- \\(U_{ij}\\) = set of users who have rated both items \\(i\\) and \\(j\\)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "369ce459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between items 1 and 2 is 0.9500\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(item1_ratings: pd.Series, item2_ratings: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two items' rating vectors.\n",
    "    Only common users are considered.\n",
    "    \n",
    "    Parameters:\n",
    "    - item1_ratings, item2_ratings: pd.Series indexed by user_id\n",
    "    \n",
    "    Returns:\n",
    "    - float: cosine similarity between -1 and 1\n",
    "    \"\"\"\n",
    "    # Find common users who rated both items\n",
    "    common_users = item1_ratings.index.intersection(item2_ratings.index)\n",
    "    \n",
    "    if len(common_users) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Extract ratings of common users\n",
    "    v1 = item1_ratings.loc[common_users]\n",
    "    v2 = item2_ratings.loc[common_users]\n",
    "\n",
    "    # Drop any NaN values (just in case)\n",
    "    valid = v1.notna() & v2.notna()\n",
    "    v1 = v1[valid]\n",
    "    v2 = v2[valid]\n",
    "\n",
    "    if len(v1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    numerator = (v1 * v2).sum()\n",
    "    denominator = np.sqrt((v1 ** 2).sum()) * np.sqrt((v2 ** 2).sum())\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "\n",
    "    result = numerator / denominator\n",
    "    return result\n",
    "\n",
    "item1, item2 = 1, 2\n",
    "item1_ratings = train_data[train_data['item_id'] == item1].set_index('user_id')['rating']\n",
    "item2_ratings = train_data[train_data['item_id'] == item2].set_index('user_id')['rating']\n",
    "print(f\"Cosine similarity between items {item1} and {item2} is {cosine_similarity(item1_ratings, item2_ratings):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b880d",
   "metadata": {},
   "source": [
    "#### C.2 Item-Item similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19385545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 796.4898 seconds\n"
     ]
    }
   ],
   "source": [
    "def compute_item_similarity_matrix(train_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute item-item similarity matrix using cosine similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame with columns ['user_id', 'item_id', 'rating']\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: item-item similarity matrix (rows & cols = item_ids)\n",
    "    \"\"\"\n",
    "    items = train_data['item_id'].unique()\n",
    "    item_similarity_matrix = pd.DataFrame(np.zeros((len(items), len(items))), index=items, columns=items)\n",
    "    \n",
    "    # Create item-rating mapping for faster lookups\n",
    "    item_ratings = {\n",
    "        item: train_data[train_data['item_id'] == item].set_index('user_id')['rating']\n",
    "        for item in items\n",
    "    }\n",
    "\n",
    "    # Compute pairwise cosine similarities\n",
    "    for i, item1 in enumerate(items):\n",
    "        for j, item2 in enumerate(items):\n",
    "            if i > j:  # Use symmetry to skip redundant computation\n",
    "                item_similarity_matrix.loc[item1, item2] = item_similarity_matrix.loc[item2, item1]\n",
    "                continue\n",
    "            if item1 == item2:\n",
    "                item_similarity_matrix.loc[item1, item2] = 1.0\n",
    "                continue\n",
    "\n",
    "            sim = cosine_similarity(item_ratings[item1], item_ratings[item2])\n",
    "            item_similarity_matrix.loc[item1, item2] = sim\n",
    "            item_similarity_matrix.loc[item2, item1] = sim  # symmetry\n",
    "    \n",
    "    return item_similarity_matrix\n",
    "\n",
    "start_time = time.time()\n",
    "item_similarity_matrix = compute_item_similarity_matrix(train_data)  \n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37879c",
   "metadata": {},
   "source": [
    "#### C.3 Implementing a function that returns k most similar item along with the similarity values to a target item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffbdb7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of item 1 are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1682, 1.0),\n",
       " (1392, 1.0),\n",
       " (1464, 1.0),\n",
       " (1108, 1.0),\n",
       " (1541, 1.0),\n",
       " (1484, 1.0),\n",
       " (1371, 1.0),\n",
       " (1537, 1.0),\n",
       " (1535, 1.0),\n",
       " (1495, 1.0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_k_item_neighbors(item_similarity_matrix: pd.DataFrame, target_item, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar items to the target item.\n",
    "    \n",
    "    Parameters:\n",
    "    - item_similarity_matrix: pd.DataFrame, item-item similarity\n",
    "    - target_item: item ID\n",
    "    - k: number of neighbors\n",
    "    \n",
    "    Returns:\n",
    "    - List of tuples: [(neighbor_item_id, similarity), ...]\n",
    "    \"\"\"\n",
    "    if target_item not in item_similarity_matrix.index:\n",
    "        return []\n",
    "\n",
    "    # Extract similarity scores for the target item\n",
    "    item_similarities = item_similarity_matrix.loc[target_item]\n",
    "\n",
    "    # Remove the target item itself\n",
    "    item_similarities = item_similarities.drop(target_item, errors='ignore')\n",
    "\n",
    "    # Sort by similarity (descending)\n",
    "    sorted_neighbors = item_similarities.sort_values(ascending=False)\n",
    "\n",
    "    # Select top-k most similar items\n",
    "    top_k = sorted_neighbors.head(k)\n",
    "\n",
    "    # Convert to list of tuples\n",
    "    top_k_neighbors = list(zip(top_k.index, top_k.values))\n",
    "\n",
    "    return top_k_neighbors\n",
    "\n",
    "target_item, k = 1, 10\n",
    "print(f\"Neighbors of item {target_item} are:\")\n",
    "get_k_item_neighbors(item_similarity_matrix, target_item, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e161805",
   "metadata": {},
   "source": [
    "#### C.4 Implementing a function that predicts the rating for a target user might give to a target item using item-item similarity matrix and the following equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac324c0",
   "metadata": {},
   "source": [
    "The **predicted rating** for a target user \\(u\\) on a target item \\(i\\) using item-based collaborative filtering is:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = \\frac{\\sum_{j \\in N(i)} s(i,j) \\cdot r_{u,j}}{\\sum_{j \\in N(i)} |s(i,j)|}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\(\\hat{r}_{u,i}\\) = predicted rating of user \\(u\\) on item \\(i\\)  \n",
    "- \\(N(i)\\) = set of top-\\(k\\) most similar items to item \\(i\\) that user \\(u\\) has rated  \n",
    "- \\(s(i,j)\\) = similarity between item \\(i\\) and item \\(j\\)  \n",
    "- \\(r_{u,j}\\) = rating of user \\(u\\) on item \\(j\\)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28235fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual rating for user 1 and item 17 is 3. The predicted rating by item-based CF for user 1 and item 17 is 3.5321\n"
     ]
    }
   ],
   "source": [
    "def predict_rating_item_based(train_data: pd.DataFrame, item_similarity_matrix: pd.DataFrame, target_user, target_item, k=5):\n",
    "    \"\"\"\n",
    "    Predict rating using item-based CF (non-mean centric).\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame ['user_id', 'item_id', 'rating']\n",
    "    - item_similarity_matrix: item-item similarity DataFrame\n",
    "    - target_user: user ID\n",
    "    - target_item: item ID\n",
    "    - k: number of neighbors to use\n",
    "    \n",
    "    Returns:\n",
    "    - float: predicted rating, or np.nan if not enough data\n",
    "    \"\"\"\n",
    "    # Get items the user has already rated\n",
    "    user_ratings = train_data[train_data['user_id'] == target_user][['item_id', 'rating']]\n",
    "    \n",
    "    if user_ratings.empty:\n",
    "        return np.nan\n",
    "\n",
    "    # Get similarities between target item and all items the user rated\n",
    "    sims = item_similarity_matrix.loc[target_item, user_ratings['item_id']]\n",
    "\n",
    "    # Combine with user's ratings\n",
    "    neighbors = pd.DataFrame({\n",
    "        'rating': user_ratings['rating'].values,\n",
    "        'similarity': sims.values\n",
    "    })\n",
    "\n",
    "    # Keep top-k most similar items\n",
    "    neighbors = neighbors.sort_values(by='similarity', ascending=False).head(k)\n",
    "\n",
    "    # Optionally, filter out items with non-positive similarity\n",
    "    neighbors = neighbors[neighbors['similarity'] > 0]\n",
    "\n",
    "    if neighbors.empty:\n",
    "        return np.nan\n",
    "\n",
    "    # Compute weighted average\n",
    "    numerator = (neighbors['rating'] * neighbors['similarity']).sum()\n",
    "    denominator = neighbors['similarity'].sum()\n",
    "\n",
    "    if denominator == 0:\n",
    "        return np.nan\n",
    "\n",
    "    predicted_rating = numerator / denominator\n",
    "\n",
    "    # Clamp to valid rating range (e.g., 1–5)\n",
    "    predicted_rating = np.clip(predicted_rating, 1, 5)\n",
    "\n",
    "    return predicted_rating\n",
    "\n",
    "\n",
    "target_user, target_item, k = 1, 17, 50\n",
    "print(f\"The actual rating for user {target_user} and item {target_item} is 3. The predicted rating by item-based CF for user {target_user} and item {target_item} is {predict_rating_item_based(train_data, item_similarity_matrix, target_user, target_item, k):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de263b97",
   "metadata": {},
   "source": [
    "#### C.5 Implement a function that generates top-K recommendation list for a target user using item-based CF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e22d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 recommendations for user 1:\n",
      "Item 1342: 5.0000\n",
      "Item 1414: 4.7500\n",
      "Item 1259: 4.5332\n",
      "Item 1354: 4.5000\n",
      "Item 1654: 4.4375\n",
      "Item 1618: 4.4000\n",
      "Item 1500: 4.4000\n",
      "Item 1332: 4.3529\n",
      "Item 1234: 4.3481\n",
      "Item 1347: 4.3276\n",
      "Item 868: 4.2604\n",
      "Item 70: 4.2585\n",
      "Item 1674: 4.2500\n",
      "Item 1678: 4.2500\n",
      "Item 1679: 4.2500\n",
      "Item 1680: 4.2500\n",
      "Item 1597: 4.2205\n",
      "Item 1447: 4.2200\n",
      "Item 1450: 4.2200\n",
      "Item 1452: 4.2200\n",
      "Item 1453: 4.2200\n",
      "Item 1460: 4.2200\n",
      "Item 1461: 4.2200\n",
      "Item 1360: 4.2069\n",
      "Item 1593: 4.2069\n",
      "Item 1677: 4.2000\n",
      "Item 174: 4.1993\n",
      "Item 64: 4.1975\n",
      "Item 177: 4.1802\n",
      "Item 1656: 4.1800\n",
      "Item 357: 4.1797\n",
      "Item 209: 4.1779\n",
      "Item 1463: 4.1779\n",
      "Item 1323: 4.1713\n",
      "Item 1398: 4.1707\n",
      "Item 671: 4.1582\n",
      "Item 1431: 4.1542\n",
      "Item 1374: 4.1500\n",
      "Item 1604: 4.1463\n",
      "Item 1601: 4.1429\n",
      "Item 435: 4.1371\n",
      "Item 210: 4.1370\n",
      "Item 705: 4.1356\n",
      "Item 1367: 4.1226\n",
      "Item 1595: 4.1212\n",
      "Item 1596: 4.1212\n",
      "Item 1123: 4.1200\n",
      "Item 1538: 4.1200\n",
      "Item 1497: 4.1200\n",
      "Item 1659: 4.1200\n"
     ]
    }
   ],
   "source": [
    "def recommend_topk_item_based(train_data, item_similarity_matrix, target_user, k=5):\n",
    "    \"\"\"\n",
    "    Generate Top-K recommendations for a target user using Item-based CF.\n",
    "    \n",
    "    Args:\n",
    "        train_data (pd.DataFrame): ratings data with columns [user_id, item_id, rating]\n",
    "        item_similarity_matrix (pd.DataFrame): precomputed item-item similarity matrix\n",
    "        target_user (int): user_id of the target user\n",
    "        k (int): number of items to recommend\n",
    "    \n",
    "    Returns:\n",
    "        list of (item_id, predicted_score) sorted by score desc\n",
    "    \"\"\"\n",
    "    # Get items the user has already rated\n",
    "    user_rated_items = set(train_data[train_data['user_id'] == target_user]['item_id'])\n",
    "\n",
    "    # All items\n",
    "    all_items = train_data['item_id'].unique()\n",
    "\n",
    "    # Candidate items = items not yet rated\n",
    "    candidate_items = [item for item in all_items if item not in user_rated_items]\n",
    "\n",
    "    predictions = []\n",
    "    for item in candidate_items:\n",
    "        pred = predict_rating_item_based(train_data, item_similarity_matrix, target_user, item, k)\n",
    "        if not np.isnan(pred):\n",
    "            predictions.append((item, pred))\n",
    "\n",
    "    # Sort by predicted rating descending\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top-k recommendations\n",
    "    result = predictions[:k]\n",
    "\n",
    "    return result\n",
    "\n",
    "target_user, k = 1, 50\n",
    "recommendations = recommend_topk_item_based(train_data, item_similarity_matrix, target_user, k)\n",
    "print(f\"Top-10 recommendations for user {target_user}:\")\n",
    "for item, score in recommendations:\n",
    "    print(f\"Item {item}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529cfade",
   "metadata": {},
   "source": [
    "### D. Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7c60388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorizationSGD:\n",
    "    \"\"\"\n",
    "    Matrix Factorization for rating prediction using Stochastic Gradient Descent (SGD).\n",
    "    \n",
    "    Rating matrix R ≈ P × Q^T + biases\n",
    "    \"\"\"\n",
    "    def __init__(self, n_factors=20, learning_rate=0.01, regularization=0.02, n_epochs=20, use_bias=True):\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        self.n_epochs = n_epochs\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        # Model parameters\n",
    "        self.P = None  # User latent factors\n",
    "        self.Q = None  # Item latent factors\n",
    "        self.user_bias = None\n",
    "        self.item_bias = None\n",
    "        self.global_mean = None\n",
    "\n",
    "    def fit(self, ratings, verbose=True):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \n",
    "        Args:\n",
    "            ratings (pd.DataFrame): dataframe with [user_id, item_id, rating]\n",
    "        \"\"\"\n",
    "        # Map IDs to indices\n",
    "        self.user_mapping = {u: i for i, u in enumerate(ratings['user_id'].unique())}\n",
    "        self.item_mapping = {i: j for j, i in enumerate(ratings['item_id'].unique())}\n",
    "        self.user_inv = {i: u for u, i in self.user_mapping.items()}\n",
    "        self.item_inv = {j: i for i, j in self.item_mapping.items()}\n",
    "\n",
    "        n_users = len(self.user_mapping)\n",
    "        n_items = len(self.item_mapping)\n",
    "\n",
    "        # Initialize factors\n",
    "        self.P = np.random.normal(0, 0.1, (n_users, self.n_factors))\n",
    "        self.Q = np.random.normal(0, 0.1, (n_items, self.n_factors))\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.user_bias = np.zeros(n_users)\n",
    "            self.item_bias = np.zeros(n_items)\n",
    "            self.global_mean = ratings['rating'].mean()\n",
    "\n",
    "        # Convert to (user_idx, item_idx, rating) triples\n",
    "        training_data = [(self.user_mapping[u], self.item_mapping[i], r)\n",
    "                         for u, i, r in zip(ratings['user_id'], ratings['item_id'], ratings['rating'])]\n",
    "\n",
    "        # SGD loop\n",
    "        for epoch in range(self.n_epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            total_error = 0\n",
    "\n",
    "            for u, i, r in training_data:\n",
    "                pred = np.dot(self.P[u], self.Q[i])\n",
    "                if self.use_bias:\n",
    "                    pred += self.global_mean + self.user_bias[u] + self.item_bias[i]\n",
    "\n",
    "                err = r - pred\n",
    "                total_error += err ** 2\n",
    "\n",
    "                # Updates\n",
    "                P_u = self.P[u]\n",
    "                Q_i = self.Q[i]\n",
    "\n",
    "                self.P[u] += self.learning_rate * (err * Q_i - self.regularization * P_u)\n",
    "                self.Q[i] += self.learning_rate * (err * P_u - self.regularization * Q_i)\n",
    "\n",
    "                if self.use_bias:\n",
    "                    self.user_bias[u] += self.learning_rate * (err - self.regularization * self.user_bias[u])\n",
    "                    self.item_bias[i] += self.learning_rate * (err - self.regularization * self.item_bias[i])\n",
    "\n",
    "            rmse = np.sqrt(total_error / len(training_data))\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{self.n_epochs} - RMSE: {rmse:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_single(self, user_id, item_id):\n",
    "        \"\"\"Predict rating for a single (user, item) pair\"\"\"\n",
    "        if user_id not in self.user_mapping or item_id not in self.item_mapping:\n",
    "            return np.nan\n",
    "\n",
    "        u = self.user_mapping[user_id]\n",
    "        i = self.item_mapping[item_id]\n",
    "\n",
    "        pred = np.dot(self.P[u], self.Q[i])\n",
    "        if self.use_bias:\n",
    "            pred += self.global_mean + self.user_bias[u] + self.item_bias[i]\n",
    "        return pred\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        \"\"\"Predict ratings for a test dataframe with [user_id, item_id]\"\"\"\n",
    "        preds = []\n",
    "        for u, i in zip(test_data['user_id'], test_data['item_id']):\n",
    "            preds.append(self.predict_single(u, i))\n",
    "        return np.array(preds)\n",
    "\n",
    "    def recommend_topk(self, user_id, train_data, n=10, exclude_seen=True):\n",
    "        \"\"\"\n",
    "        Generate Top-K recommendations for a given user.\n",
    "\n",
    "        Args:\n",
    "            user_id (int): target user ID (original ID, not index).\n",
    "            train_data (pd.DataFrame): training ratings [user_id, item_id, rating],\n",
    "                                       used to exclude already-seen items.\n",
    "            k (int): number of recommendations.\n",
    "            exclude_seen (bool): whether to exclude items the user already rated.\n",
    "\n",
    "        Returns:\n",
    "            list of (item_id, predicted_score) sorted by score desc.\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_mapping:\n",
    "            return []\n",
    "\n",
    "        u = self.user_mapping[user_id]\n",
    "\n",
    "        # Predict scores for all items\n",
    "        scores = np.dot(self.P[u], self.Q.T)\n",
    "        if self.use_bias:\n",
    "            scores += self.global_mean + self.user_bias[u] + self.item_bias\n",
    "\n",
    "        # Exclude seen items\n",
    "        if exclude_seen:\n",
    "            seen_items = train_data[train_data['user_id'] == user_id]['item_id'].values\n",
    "            seen_idx = [self.item_mapping[i] for i in seen_items if i in self.item_mapping]\n",
    "            scores[seen_idx] = -np.inf\n",
    "\n",
    "        # Get top-K items\n",
    "        top_idx = np.argsort(scores)[::-1][:n]\n",
    "        top_items = [self.item_inv[i] for i in top_idx]\n",
    "        top_scores = scores[top_idx]\n",
    "\n",
    "        return list(zip(top_items, top_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f030b0",
   "metadata": {},
   "source": [
    "### E. Bayesian Probabilistic Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0155e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianPersonalizedRanking:\n",
    "    def __init__(self, n_factors=50, learning_rate=0.01, regularization=0.01, n_epochs=20):\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "    def fit(self, train_data, verbose=True):\n",
    "        \"\"\"\n",
    "        train_data: DataFrame with columns ['user_id', 'item_id']\n",
    "        \"\"\"\n",
    "        users = train_data['user_id'].unique()\n",
    "        items = train_data['item_id'].unique()\n",
    "\n",
    "        self.user_mapping = {u: i for i, u in enumerate(users)}\n",
    "        self.item_mapping = {i: j for j, i in enumerate(items)}\n",
    "        self.user_inv = {i: u for u, i in self.user_mapping.items()}\n",
    "        self.item_inv = {j: i for i, j in self.item_mapping.items()}\n",
    "\n",
    "        n_users = len(users)\n",
    "        n_items = len(items)\n",
    "\n",
    "        # Initialize latent factors\n",
    "        self.P = np.random.normal(0, 0.1, (n_users, self.n_factors))\n",
    "        self.Q = np.random.normal(0, 0.1, (n_items, self.n_factors))\n",
    "\n",
    "        # Convert data to user->positive items\n",
    "        user_pos_items = train_data.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            total_loss = 0\n",
    "            for _ in range(len(train_data)):\n",
    "                # Sample user, positive item, and negative item\n",
    "                u = np.random.choice(users)\n",
    "                pos_items = user_pos_items[u]\n",
    "                i = np.random.choice(list(pos_items))\n",
    "                j = np.random.choice(list(items - pos_items)) if isinstance(items, set) else np.random.choice([it for it in items if it not in pos_items])\n",
    "\n",
    "                u_idx, i_idx, j_idx = self.user_mapping[u], self.item_mapping[i], self.item_mapping[j]\n",
    "\n",
    "                # Compute predicted preference difference\n",
    "                x_uij = np.dot(self.P[u_idx], self.Q[i_idx] - self.Q[j_idx])\n",
    "                sigmoid = 1 / (1 + np.exp(-x_uij))\n",
    "\n",
    "                # Gradients\n",
    "                dP = (1 - sigmoid) * (self.Q[i_idx] - self.Q[j_idx]) - self.regularization * self.P[u_idx]\n",
    "                dQi = (1 - sigmoid) * self.P[u_idx] - self.regularization * self.Q[i_idx]\n",
    "                dQj = -(1 - sigmoid) * self.P[u_idx] - self.regularization * self.Q[j_idx]\n",
    "\n",
    "                # Updates\n",
    "                self.P[u_idx] += self.learning_rate * dP\n",
    "                self.Q[i_idx] += self.learning_rate * dQi\n",
    "                self.Q[j_idx] += self.learning_rate * dQj\n",
    "\n",
    "                total_loss += -np.log(sigmoid)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{self.n_epochs} - Loss: {total_loss/len(train_data):.4f}\")\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        if user_id not in self.user_mapping or item_id not in self.item_mapping:\n",
    "            return np.nan\n",
    "        u, i = self.user_mapping[user_id], self.item_mapping[item_id]\n",
    "        return np.dot(self.P[u], self.Q[i])\n",
    "\n",
    "    def recommend_topk(self, user_id, train_data=None, k=10):\n",
    "        if user_id not in self.user_mapping:\n",
    "            return []\n",
    "\n",
    "        u = self.user_mapping[user_id]\n",
    "        scores = np.dot(self.P[u], self.Q.T)\n",
    "        if train_data is not None:\n",
    "            seen_items = set(train_data[train_data['user_id'] == user_id]['item_id'])\n",
    "            item_indices = [self.item_mapping[i] for i in seen_items if i in self.item_mapping]\n",
    "            scores[item_indices] = -np.inf\n",
    "\n",
    "        top_indices = np.argsort(scores)[::-1][:k]\n",
    "        top_items = [self.item_inv[i] for i in top_indices]\n",
    "        return list(zip(top_items, scores[top_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6cc4c0",
   "metadata": {},
   "source": [
    "### F. Recommender Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b38977",
   "metadata": {},
   "source": [
    "#### F.1 Content-Based Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f3f451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating  timestamp   CB_pred  UserKNN_pred  \\\n",
      "0            1        6       5  887431973  3.181903      3.350398   \n",
      "1            1       10       3  875693118  3.105171      3.718863   \n",
      "2            1       12       5  878542960  3.073604      4.214966   \n",
      "3            1       14       5  874965706  3.022041      3.849813   \n",
      "4            1       17       3  875073198  3.110275      3.528334   \n",
      "...        ...      ...     ...        ...       ...           ...   \n",
      "19995      458      648       4  886395899  3.413353      3.750399   \n",
      "19996      458     1101       4  886397931  3.366645      3.721086   \n",
      "19997      459      934       3  879563639  3.408989      3.132601   \n",
      "19998      460       10       3  882912371  3.146658      3.738442   \n",
      "19999      462      682       5  886365231  3.476906      3.609195   \n",
      "\n",
      "       ItemKNN_pred   MF_pred  CB_pred_full_avg  \n",
      "0          3.659467  3.530998          3.181903  \n",
      "1          3.880544  3.632905          3.105171  \n",
      "2          3.966615  4.368910          3.073604  \n",
      "3          3.878583  3.868836          3.022041  \n",
      "4          3.640701  3.512230          3.110275  \n",
      "...             ...       ...               ...  \n",
      "19995      3.816501  3.714632          3.413353  \n",
      "19996      4.075090  3.645308          3.366645  \n",
      "19997      3.520428  3.131335          3.408989  \n",
      "19998      3.584967  3.700987          3.146658  \n",
      "19999      4.123499  3.253819          3.476906  \n",
      "\n",
      "[20000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def content_based_rating_prediction(train_data, test_data, content_type, aggregation_method):\n",
    "    \"\"\"\n",
    "    Predict ratings for user-item pairs in test_data using a content-based model.\n",
    "    Scales predictions to the [1, 5] interval.\n",
    "    \"\"\"\n",
    "    # Precompute all item embeddings\n",
    "    item_embs = {item_id: get_item_emb(item_id, content_type)\n",
    "                 for item_id in train_data['item_id'].unique()}\n",
    "\n",
    "    # Precompute all user embeddings\n",
    "    user_embs = {user_id: get_user_emb(train_data, user_id, content_type, aggregation_method)\n",
    "                 for user_id in train_data['user_id'].unique()}\n",
    "\n",
    "    # Predict raw ratings\n",
    "    def safe_dot(u, i):\n",
    "        if u not in user_embs or i not in item_embs:\n",
    "            return np.nan\n",
    "        return float(np.dot(user_embs[u], item_embs[i]))\n",
    "\n",
    "    raw_preds = [safe_dot(u, i) for u, i in zip(test_data['user_id'], test_data['item_id'])]\n",
    "    raw_preds = np.array(raw_preds, dtype=float)\n",
    "\n",
    "    # Compute min and max of non-NaN predictions\n",
    "    valid_mask = ~np.isnan(raw_preds)\n",
    "    min_val, max_val = raw_preds[valid_mask].min(), raw_preds[valid_mask].max()\n",
    "\n",
    "    # Normalize to [1, 5] using formula: 1 + (pred - min_val) * 4 / (max_val - min_val)\n",
    "    scaled_preds = raw_preds.copy()\n",
    "    if max_val > min_val:\n",
    "        scaled_preds[valid_mask] = 1 + (raw_preds[valid_mask] - min_val) * (4.0 / (max_val - min_val))\n",
    "    else:\n",
    "        # if all predictions are the same, just clip to 1-5\n",
    "        scaled_preds[valid_mask] = np.clip(raw_preds[valid_mask], 1.0, 5.0)\n",
    "\n",
    "    # Store predictions in test_data\n",
    "    # test_data = test_data.copy()\n",
    "    test_data[f'CB_pred_{content_type}_{aggregation_method}'] = scaled_preds\n",
    "\n",
    "    return test_data\n",
    "\n",
    "\n",
    "content_based_rating_prediction(train_data, test_data, 'full', 'avg')\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5988f",
   "metadata": {},
   "source": [
    "#### F.2 User-based neighborhood method Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c3736a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting UserCF ratings: 100%|██████████| 20000/20000 [01:25<00:00, 234.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating  timestamp   CB_pred  UserKNN_pred  \\\n",
      "0            1        6       5  887431973  3.181903      3.350398   \n",
      "1            1       10       3  875693118  3.105171      3.718863   \n",
      "2            1       12       5  878542960  3.073604      4.214966   \n",
      "3            1       14       5  874965706  3.022041      3.849813   \n",
      "4            1       17       3  875073198  3.110275      3.528334   \n",
      "...        ...      ...     ...        ...       ...           ...   \n",
      "19995      458      648       4  886395899  3.413353      3.750399   \n",
      "19996      458     1101       4  886397931  3.366645      3.721086   \n",
      "19997      459      934       3  879563639  3.408989      3.132601   \n",
      "19998      460       10       3  882912371  3.146658      3.738442   \n",
      "19999      462      682       5  886365231  3.476906      3.609195   \n",
      "\n",
      "       ItemKNN_pred   MF_pred  CB_pred_full_avg  CB_pred_title_genres_avg  \\\n",
      "0          3.659467  3.530998          3.181903                  3.550445   \n",
      "1          3.880544  3.632905          3.105171                  4.123773   \n",
      "2          3.966615  4.368910          3.073604                  4.059065   \n",
      "3          3.878583  3.868836          3.022041                  4.430644   \n",
      "4          3.640701  3.512230          3.110275                  3.044228   \n",
      "...             ...       ...               ...                       ...   \n",
      "19995      3.816501  3.714632          3.413353                  4.365108   \n",
      "19996      4.075090  3.645308          3.366645                  4.564920   \n",
      "19997      3.520428  3.131335          3.408989                  4.234614   \n",
      "19998      3.584967  3.700987          3.146658                  4.333253   \n",
      "19999      4.123499  3.253819          3.476906                  4.221904   \n",
      "\n",
      "       CB_pred_title_genres_weighted_avg  CB_pred_title_genres_avg_pos  \\\n",
      "0                               3.468300                      3.507790   \n",
      "1                               4.013016                      4.035019   \n",
      "2                               3.953977                      3.984362   \n",
      "3                               4.316426                      4.334695   \n",
      "4                               2.932724                      2.959895   \n",
      "...                                  ...                           ...   \n",
      "19995                           4.201680                      4.166159   \n",
      "19996                           4.387995                      4.337482   \n",
      "19997                           4.059179                      4.027467   \n",
      "19998                           4.170318                      4.117563   \n",
      "19999                           4.072106                      4.061584   \n",
      "\n",
      "       CB_pred_description_avg  CB_pred_description_weighted_avg  \\\n",
      "0                     3.189063                          3.073861   \n",
      "1                     3.110267                          2.995651   \n",
      "2                     3.031760                          2.918576   \n",
      "3                     2.994979                          2.900070   \n",
      "4                     2.935336                          2.827003   \n",
      "...                        ...                               ...   \n",
      "19995                 3.197704                          3.085112   \n",
      "19996                 3.136578                          3.028946   \n",
      "19997                 3.284834                          3.155059   \n",
      "19998                 3.150456                          3.049190   \n",
      "19999                 3.345996                          3.220253   \n",
      "\n",
      "       CB_pred_description_avg_pos  CB_pred_full_weighted_avg  \\\n",
      "0                         3.031285                   3.072459   \n",
      "1                         2.948862                   2.994448   \n",
      "2                         2.883661                   2.962424   \n",
      "3                         2.865145                   2.926361   \n",
      "4                         2.798892                   2.998877   \n",
      "...                            ...                        ...   \n",
      "19995                     3.056954                   3.297858   \n",
      "19996                     3.000683                   3.253845   \n",
      "19997                     3.108343                   3.278825   \n",
      "19998                     3.062683                   3.049638   \n",
      "19999                     3.190037                   3.352545   \n",
      "\n",
      "       CB_pred_full_avg_pos  UserKNN_pred_5  \n",
      "0                  3.034986        2.862754  \n",
      "1                  2.952175        3.727217  \n",
      "2                  2.929757        4.243602  \n",
      "3                  2.889250        3.977176  \n",
      "4                  2.970257        3.780217  \n",
      "...                     ...             ...  \n",
      "19995              3.273925        3.638334  \n",
      "19996              3.226820        3.718598  \n",
      "19997              3.242974        2.962789  \n",
      "19998              3.058756        3.931356  \n",
      "19999              3.327689        3.147627  \n",
      "\n",
      "[20000 rows x 18 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def user_based_rating_prediction(train_data, user_similarity_matrix, test_data, k):\n",
    "    \"\"\"\n",
    "    Predict user-based CF ratings for all (user, item) pairs in test_data,\n",
    "    and normalize predictions to [1, 5] using min-max scaling.\n",
    "    \"\"\"\n",
    "    pred_ratings = []\n",
    "\n",
    "    for _, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Predicting UserCF ratings\"):\n",
    "        target_user = row['user_id']\n",
    "        target_item = row['item_id']\n",
    "\n",
    "        # Check if target_user and target_item exist\n",
    "        if target_user not in user_similarity_matrix.index or target_item not in train_data['item_id'].unique():\n",
    "            pred_ratings.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Target user's mean rating\n",
    "        target_user_ratings = train_data[train_data['user_id'] == target_user]['rating']\n",
    "        if target_user_ratings.empty:\n",
    "            pred_ratings.append(np.nan)\n",
    "            continue\n",
    "        target_user_mean = target_user_ratings.mean()\n",
    "\n",
    "        # Users who rated target item\n",
    "        item_raters = train_data[train_data['item_id'] == target_item]\n",
    "        if item_raters.empty:\n",
    "            pred_ratings.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Similarities between target user and raters\n",
    "        similarities = user_similarity_matrix.loc[target_user, item_raters['user_id']]\n",
    "        item_raters = item_raters.copy()\n",
    "        item_raters['similarity'] = similarities.values\n",
    "\n",
    "        # Top-k neighbors with positive similarity\n",
    "        item_raters = item_raters[item_raters['similarity'] > 0].sort_values(by='similarity', ascending=False).head(k)\n",
    "        if item_raters.empty:\n",
    "            pred_ratings.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Mean-centered ratings\n",
    "        neighbor_means = train_data.groupby('user_id')['rating'].mean().reindex(item_raters['user_id'])\n",
    "        item_raters['mean_centered'] = item_raters['rating'] - neighbor_means.values\n",
    "\n",
    "        numerator = (item_raters['similarity'] * item_raters['mean_centered']).sum()\n",
    "        denominator = item_raters['similarity'].abs().sum()\n",
    "\n",
    "        predicted_rating = target_user_mean + numerator / denominator\n",
    "        pred_ratings.append(predicted_rating)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    pred_ratings = np.array(pred_ratings, dtype=float)\n",
    "\n",
    "    # Min-max normalization over valid predictions\n",
    "    valid_mask = ~np.isnan(pred_ratings)\n",
    "    min_val, max_val = pred_ratings[valid_mask].min(), pred_ratings[valid_mask].max()\n",
    "    if max_val > min_val:\n",
    "        pred_ratings[valid_mask] = 1 + (pred_ratings[valid_mask] - min_val) * (4.0 / (max_val - min_val))\n",
    "    else:\n",
    "        pred_ratings[valid_mask] = np.clip(pred_ratings[valid_mask], 1, 5)\n",
    "\n",
    "    # Add predictions to test_data\n",
    "    test_data[f'UserKNN_pred_{k}'] = pred_ratings\n",
    "\n",
    "    return test_data\n",
    "\n",
    "user_based_rating_prediction(train_data, user_similarity_matrix, test_data, 5)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0a471",
   "metadata": {},
   "source": [
    "#### F.3 Item-based neighborhood method Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d511de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ItemCF ratings: 100%|██████████| 20000/20000 [00:10<00:00, 1898.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating  timestamp   CB_pred  UserKNN_pred  \\\n",
      "0            1        6       5  887431973  3.181903      3.350398   \n",
      "1            1       10       3  875693118  3.105171      3.718863   \n",
      "2            1       12       5  878542960  3.073604      4.214966   \n",
      "3            1       14       5  874965706  3.022041      3.849813   \n",
      "4            1       17       3  875073198  3.110275      3.528334   \n",
      "...        ...      ...     ...        ...       ...           ...   \n",
      "19995      458      648       4  886395899  3.413353      3.750399   \n",
      "19996      458     1101       4  886397931  3.366645      3.721086   \n",
      "19997      459      934       3  879563639  3.408989      3.132601   \n",
      "19998      460       10       3  882912371  3.146658      3.738442   \n",
      "19999      462      682       5  886365231  3.476906      3.609195   \n",
      "\n",
      "       ItemKNN_pred   MF_pred  CB_pred_full_avg  CB_pred_title_genres_avg  \\\n",
      "0          3.659467  3.530998          3.181903                  3.550445   \n",
      "1          3.880544  3.632905          3.105171                  4.123773   \n",
      "2          3.966615  4.368910          3.073604                  4.059065   \n",
      "3          3.878583  3.868836          3.022041                  4.430644   \n",
      "4          3.640701  3.512230          3.110275                  3.044228   \n",
      "...             ...       ...               ...                       ...   \n",
      "19995      3.816501  3.714632          3.413353                  4.365108   \n",
      "19996      4.075090  3.645308          3.366645                  4.564920   \n",
      "19997      3.520428  3.131335          3.408989                  4.234614   \n",
      "19998      3.584967  3.700987          3.146658                  4.333253   \n",
      "19999      4.123499  3.253819          3.476906                  4.221904   \n",
      "\n",
      "       CB_pred_title_genres_weighted_avg  CB_pred_title_genres_avg_pos  \\\n",
      "0                               3.468300                      3.507790   \n",
      "1                               4.013016                      4.035019   \n",
      "2                               3.953977                      3.984362   \n",
      "3                               4.316426                      4.334695   \n",
      "4                               2.932724                      2.959895   \n",
      "...                                  ...                           ...   \n",
      "19995                           4.201680                      4.166159   \n",
      "19996                           4.387995                      4.337482   \n",
      "19997                           4.059179                      4.027467   \n",
      "19998                           4.170318                      4.117563   \n",
      "19999                           4.072106                      4.061584   \n",
      "\n",
      "       CB_pred_description_avg  CB_pred_description_weighted_avg  \\\n",
      "0                     3.189063                          3.073861   \n",
      "1                     3.110267                          2.995651   \n",
      "2                     3.031760                          2.918576   \n",
      "3                     2.994979                          2.900070   \n",
      "4                     2.935336                          2.827003   \n",
      "...                        ...                               ...   \n",
      "19995                 3.197704                          3.085112   \n",
      "19996                 3.136578                          3.028946   \n",
      "19997                 3.284834                          3.155059   \n",
      "19998                 3.150456                          3.049190   \n",
      "19999                 3.345996                          3.220253   \n",
      "\n",
      "       CB_pred_description_avg_pos  CB_pred_full_weighted_avg  \\\n",
      "0                         3.031285                   3.072459   \n",
      "1                         2.948862                   2.994448   \n",
      "2                         2.883661                   2.962424   \n",
      "3                         2.865145                   2.926361   \n",
      "4                         2.798892                   2.998877   \n",
      "...                            ...                        ...   \n",
      "19995                     3.056954                   3.297858   \n",
      "19996                     3.000683                   3.253845   \n",
      "19997                     3.108343                   3.278825   \n",
      "19998                     3.062683                   3.049638   \n",
      "19999                     3.190037                   3.352545   \n",
      "\n",
      "       CB_pred_full_avg_pos  UserKNN_pred_5  ItemKNN_pred_5  \n",
      "0                  3.034986        2.862754        3.000000  \n",
      "1                  2.952175        3.727217        2.599449  \n",
      "2                  2.929757        4.243602        2.393287  \n",
      "3                  2.889250        3.977176        2.200000  \n",
      "4                  2.970257        3.780217        3.000000  \n",
      "...                     ...             ...             ...  \n",
      "19995              3.273925        3.638334        2.600000  \n",
      "19996              3.226820        3.718598        3.396667  \n",
      "19997              3.242974        2.962789        3.600856  \n",
      "19998              3.058756        3.931356        3.198217  \n",
      "19999              3.327689        3.147627        4.799286  \n",
      "\n",
      "[20000 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def item_based_rating_prediction(train_data, item_similarity_matrix, test_data, k):\n",
    "    \"\"\"\n",
    "    Predict item-based CF ratings for all (user, item) pairs in test_data,\n",
    "    and normalize predictions to [1,5] using min-max scaling.\n",
    "    \"\"\"\n",
    "    pred_ratings = []\n",
    "\n",
    "    for _, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Predicting ItemCF ratings\"):\n",
    "        target_user = row['user_id']\n",
    "        target_item = row['item_id']\n",
    "\n",
    "        # Users who rated the target item\n",
    "        user_ratings = train_data[train_data['user_id'] == target_user]\n",
    "        if user_ratings.empty or target_item not in item_similarity_matrix.index:\n",
    "            pred_ratings.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Compute similarities between target item and items rated by user\n",
    "        rated_items = user_ratings['item_id'].values\n",
    "        sims = item_similarity_matrix.loc[target_item, rated_items]\n",
    "        top_k_idx = np.argsort(-sims.values)[:k]  # top-k most similar\n",
    "        top_k_sims = sims.values[top_k_idx]\n",
    "        top_k_ratings = user_ratings['rating'].values[top_k_idx]\n",
    "\n",
    "        # Keep only positive similarities\n",
    "        mask = top_k_sims > 0\n",
    "        if not mask.any():\n",
    "            pred_ratings.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        numerator = (top_k_sims[mask] * top_k_ratings[mask]).sum()\n",
    "        denominator = top_k_sims[mask].sum()\n",
    "        predicted_rating = numerator / denominator\n",
    "        pred_ratings.append(predicted_rating)\n",
    "\n",
    "    # Convert to numpy array and normalize\n",
    "    pred_ratings = np.array(pred_ratings, dtype=float)\n",
    "    valid_mask = ~np.isnan(pred_ratings)\n",
    "    min_val, max_val = pred_ratings[valid_mask].min(), pred_ratings[valid_mask].max()\n",
    "    if max_val > min_val:\n",
    "        pred_ratings[valid_mask] = 1 + (pred_ratings[valid_mask] - min_val) * (4.0 / (max_val - min_val))\n",
    "    else:\n",
    "        pred_ratings[valid_mask] = np.clip(pred_ratings[valid_mask], 1, 5)\n",
    "\n",
    "    # Store in DataFrame\n",
    "    test_data[f'ItemKNN_pred_{k}'] = pred_ratings\n",
    "\n",
    "    return test_data\n",
    "\n",
    "item_based_rating_prediction(train_data, item_similarity_matrix, test_data, 5)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6fd1ac",
   "metadata": {},
   "source": [
    "#### F.4 Matrix Factorization Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab0df0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - RMSE: 1.0962\n",
      "Epoch 2/10 - RMSE: 1.0569\n",
      "Epoch 3/10 - RMSE: 1.0308\n",
      "Epoch 4/10 - RMSE: 1.0121\n",
      "Epoch 5/10 - RMSE: 0.9980\n",
      "Epoch 6/10 - RMSE: 0.9869\n",
      "Epoch 7/10 - RMSE: 0.9779\n",
      "Epoch 8/10 - RMSE: 0.9704\n",
      "Epoch 9/10 - RMSE: 0.9640\n",
      "Epoch 10/10 - RMSE: 0.9585\n",
      "       user_id  item_id  rating  timestamp   CB_pred  UserKNN_pred  \\\n",
      "0            1        6       5  887431973  3.181903      3.350398   \n",
      "1            1       10       3  875693118  3.105171      3.718863   \n",
      "2            1       12       5  878542960  3.073604      4.214966   \n",
      "3            1       14       5  874965706  3.022041      3.849813   \n",
      "4            1       17       3  875073198  3.110275      3.528334   \n",
      "...        ...      ...     ...        ...       ...           ...   \n",
      "19995      458      648       4  886395899  3.413353      3.750399   \n",
      "19996      458     1101       4  886397931  3.366645      3.721086   \n",
      "19997      459      934       3  879563639  3.408989      3.132601   \n",
      "19998      460       10       3  882912371  3.146658      3.738442   \n",
      "19999      462      682       5  886365231  3.476906      3.609195   \n",
      "\n",
      "       ItemKNN_pred   MF_pred  CB_pred_full_avg  CB_pred_title_genres_avg  \\\n",
      "0          3.659467  3.530998          3.181903                  3.550445   \n",
      "1          3.880544  3.632905          3.105171                  4.123773   \n",
      "2          3.966615  4.368910          3.073604                  4.059065   \n",
      "3          3.878583  3.868836          3.022041                  4.430644   \n",
      "4          3.640701  3.512230          3.110275                  3.044228   \n",
      "...             ...       ...               ...                       ...   \n",
      "19995      3.816501  3.714632          3.413353                  4.365108   \n",
      "19996      4.075090  3.645308          3.366645                  4.564920   \n",
      "19997      3.520428  3.131335          3.408989                  4.234614   \n",
      "19998      3.584967  3.700987          3.146658                  4.333253   \n",
      "19999      4.123499  3.253819          3.476906                  4.221904   \n",
      "\n",
      "       ...  ItemKNN_pred_26  ItemKNN_pred_27  ItemKNN_pred_28  \\\n",
      "0      ...         3.077651         3.130685         3.161860   \n",
      "1      ...         3.740354         3.812120         3.855070   \n",
      "2      ...         3.974369         3.926401         3.965561   \n",
      "3      ...         3.813567         3.845782         3.887684   \n",
      "4      ...         3.461050         3.465970         3.485054   \n",
      "...    ...              ...              ...              ...   \n",
      "19995  ...         3.468040         3.548085         3.564607   \n",
      "19996  ...         3.939998         3.968609         4.006239   \n",
      "19997  ...         3.509246         3.512567         3.494055   \n",
      "19998  ...         3.549304         3.589075         3.567802   \n",
      "19999  ...         4.147830         4.206657         4.097930   \n",
      "\n",
      "       ItemKNN_pred_29  ItemKNN_pred_31  ItemKNN_pred_32  ItemKNN_pred_33  \\\n",
      "0             3.225356         3.307599         3.329143         3.306948   \n",
      "1             3.895008         3.837129         3.810770         3.807850   \n",
      "2             3.931707         3.936622         3.938671         3.994644   \n",
      "3             3.891662         3.964502         3.870753         3.835457   \n",
      "4             3.502781         3.535032         3.456104         3.522302   \n",
      "...                ...              ...              ...              ...   \n",
      "19995         3.579957         3.607918         3.620402         3.590699   \n",
      "19996         3.970970         3.940464         3.974105         3.998230   \n",
      "19997         3.476871         3.478718         3.495177         3.561101   \n",
      "19998         3.548020         3.545245         3.496477         3.562417   \n",
      "19999         4.062171         4.027626         4.055651         4.077396   \n",
      "\n",
      "       ItemKNN_pred_34  MF_pred_50  MF_pred_50_0.001_0.001_10  \n",
      "0             3.356935    3.621474                   3.512464  \n",
      "1             3.843482    3.713548                   3.738089  \n",
      "2             4.024951    4.454423                   4.382681  \n",
      "3             3.810488    3.907008                   3.890399  \n",
      "4             3.448023    3.511683                   3.381709  \n",
      "...                ...         ...                        ...  \n",
      "19995         3.603069    3.799686                   3.808689  \n",
      "19996         4.028383    3.615943                   3.769577  \n",
      "19997         3.514496    3.205167                   3.147991  \n",
      "19998         3.575533    3.430226                   3.563211  \n",
      "19999         4.074661    3.521584                   3.435900  \n",
      "\n",
      "[20000 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "def mf_rating_prediction(mf_model, test_data):\n",
    "    \"\"\"\n",
    "    Predict ratings using trained Matrix Factorization model.\n",
    "    Normalize predictions to [1,5] using min-max scaling.\n",
    "    \n",
    "    Parameters:\n",
    "    - mf_model: trained MF model with predict(user_id, item_id) method\n",
    "    - test_data: DataFrame with 'user_id' and 'item_id'\n",
    "    \"\"\"\n",
    "    raw_preds = mf_model.predict(test_data)\n",
    "    raw_preds = np.array(raw_preds, dtype=float)\n",
    "\n",
    "    # # Compute min-max on valid predictions\n",
    "    # valid_mask = ~np.isnan(raw_preds)\n",
    "    # min_val, max_val = raw_preds[valid_mask].min(), raw_preds[valid_mask].max()\n",
    "\n",
    "    # # Scale to [1,5]\n",
    "    # scaled_preds = raw_preds.copy()\n",
    "    # if max_val > min_val:\n",
    "    #     scaled_preds[valid_mask] = 1 + (raw_preds[valid_mask] - min_val) * (4.0 / (max_val - min_val))\n",
    "    # else:\n",
    "    #     scaled_preds[valid_mask] = np.clip(raw_preds[valid_mask], 1, 5)\n",
    "\n",
    "    # test_data['MF_pred'] = scaled_preds\n",
    "    test_data[f'MF_pred_{mf_model.n_factors}_{mf_model.learning_rate}_{mf_model.regularization}_{mf_model.n_epochs}'] = raw_preds\n",
    "    return test_data\n",
    "\n",
    "# test_data = test_data.drop('MF_pred_RAW', axis=1)\n",
    "mf = MatrixFactorizationSGD(n_factors=50, learning_rate=0.001, regularization=0.001, n_epochs=10)\n",
    "mf.fit(train_data, verbose=True)\n",
    "mf_rating_prediction(mf, test_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98dbe2",
   "metadata": {},
   "source": [
    "### G. Hybrid Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c3a82",
   "metadata": {},
   "source": [
    "$$ score(u, i) = \\sum_{j=1}^k \\alpha_j score_{C_j} (u, i) $$\n",
    "\n",
    "Where:\n",
    "-  $\\alpha_j$ = Coefficient weight, the degree to which\n",
    "component 𝐶𝑗 contributes to final prediction\n",
    "- $score_{C_j} (u, i)$ = Prediction Score for user u and item i by algorithm j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a9d85fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting UserCF ratings: 100%|██████████| 20000/20000 [01:15<00:00, 265.28it/s]\n",
      "Predicting ItemCF ratings: 100%|██████████| 20000/20000 [00:09<00:00, 2187.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - RMSE: 1.0958\n",
      "Epoch 2/10 - RMSE: 1.0566\n",
      "Epoch 3/10 - RMSE: 1.0305\n",
      "Epoch 4/10 - RMSE: 1.0118\n",
      "Epoch 5/10 - RMSE: 0.9977\n",
      "Epoch 6/10 - RMSE: 0.9866\n",
      "Epoch 7/10 - RMSE: 0.9776\n",
      "Epoch 8/10 - RMSE: 0.9702\n",
      "Epoch 9/10 - RMSE: 0.9638\n",
      "Epoch 10/10 - RMSE: 0.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting UserCF ratings: 100%|██████████| 80000/80000 [06:16<00:00, 212.49it/s]\n",
      "Predicting ItemCF ratings: 100%|██████████| 80000/80000 [00:46<00:00, 1732.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - RMSE: 1.0959\n",
      "Epoch 2/10 - RMSE: 1.0566\n",
      "Epoch 3/10 - RMSE: 1.0304\n",
      "Epoch 4/10 - RMSE: 1.0117\n",
      "Epoch 5/10 - RMSE: 0.9976\n",
      "Epoch 6/10 - RMSE: 0.9865\n",
      "Epoch 7/10 - RMSE: 0.9774\n",
      "Epoch 8/10 - RMSE: 0.9699\n",
      "Epoch 9/10 - RMSE: 0.9636\n",
      "Epoch 10/10 - RMSE: 0.9580\n",
      "Learned weights (α1, α2, α3, α4): [ 0.01786396  2.32627634  0.32726678 -1.2449326 ]\n",
      "Intercept: -1.160096503254214\n",
      "       user_id  item_id  rating  timestamp   CB_pred  UserKNN_pred  \\\n",
      "0            1        6       5  887431973  3.181903      3.350398   \n",
      "1            1       10       3  875693118  3.105171      3.718863   \n",
      "2            1       12       5  878542960  3.073604      4.214966   \n",
      "3            1       14       5  874965706  3.022041      3.849813   \n",
      "4            1       17       3  875073198  3.110275      3.528334   \n",
      "...        ...      ...     ...        ...       ...           ...   \n",
      "19995      458      648       4  886395899  3.413353      3.750399   \n",
      "19996      458     1101       4  886397931  3.366645      3.721086   \n",
      "19997      459      934       3  879563639  3.408989      3.132601   \n",
      "19998      460       10       3  882912371  3.146658      3.738442   \n",
      "19999      462      682       5  886365231  3.476906      3.609195   \n",
      "\n",
      "       ItemKNN_pred   MF_pred  Hybrid_pred  \n",
      "0          3.659467  3.530998     3.492465  \n",
      "1          3.880544  3.632905     4.293727  \n",
      "2          3.966615  4.368910     4.559127  \n",
      "3          3.878583  3.868836     4.302509  \n",
      "4          3.640701  3.512230     3.922337  \n",
      "...             ...       ...          ...  \n",
      "19995      3.816501  3.714632     4.249891  \n",
      "19996      4.075090  3.645308     4.351799  \n",
      "19997      3.520428  3.131335     3.441914  \n",
      "19998      3.584967  3.700987     4.158527  \n",
      "19999      4.123499  3.253819     4.596698  \n",
      "\n",
      "[19940 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Content-Based\n",
    "test_data = content_based_rating_prediction(train_data, test_data, 'full', 'avg')\n",
    "\n",
    "# UserKNN\n",
    "test_data = user_based_rating_prediction(train_data, user_similarity_matrix, test_data, k=50)\n",
    "\n",
    "# ItemKNN\n",
    "test_data = item_based_rating_prediction(train_data, item_similarity_matrix, test_data, k=50)\n",
    "\n",
    "# Matrix Factorization\n",
    "mf = MatrixFactorizationSGD(n_factors=50, n_epochs=10, learning_rate=0.001, regularization=0.001)\n",
    "mf.fit(train_data, verbose=True)\n",
    "test_data = mf_rating_prediction(mf, test_data)\n",
    "\n",
    "# Content-Based\n",
    "train_data = content_based_rating_prediction(train_data, train_data, 'full', 'avg')\n",
    "\n",
    "# UserKNN\n",
    "train_data = user_based_rating_prediction(train_data, user_similarity_matrix, train_data, k=50)\n",
    "\n",
    "# ItemKNN\n",
    "train_data = item_based_rating_prediction(train_data, item_similarity_matrix, train_data, k=50)\n",
    "\n",
    "# Matrix Factorization\n",
    "mf = MatrixFactorizationSGD(n_factors=50, n_epochs=10, learning_rate=0.001, regularization=0.001)\n",
    "mf.fit(train_data, verbose=True)\n",
    "train_data = mf_rating_prediction(mf, train_data)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Keep only rows where all predictions are valid\n",
    "valid_mask = train_data[['CB_pred', 'UserKNN_pred', 'ItemKNN_pred', 'MF_pred']].notna().all(axis=1)\n",
    "df_train_valid = train_data[valid_mask]\n",
    "\n",
    "X_train = df_train_valid[['CB_pred', 'UserKNN_pred', 'ItemKNN_pred', 'MF_pred']].values\n",
    "y_train = df_train_valid['rating'].values\n",
    "\n",
    "reg = LinearRegression(fit_intercept=True)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Learned weights (α1, α2, α3, α4):\", reg.coef_)\n",
    "print(\"Intercept:\", reg.intercept_)\n",
    "\n",
    "valid_mask = test_data[['CB_pred', 'UserKNN_pred', 'ItemKNN_pred', 'MF_pred']].notna().all(axis=1)\n",
    "df_test_valid = test_data[valid_mask]\n",
    "\n",
    "X_test = df_test_valid[['CB_pred', 'UserKNN_pred', 'ItemKNN_pred', 'MF_pred']].values\n",
    "df_test_valid['Hybrid_pred'] = reg.predict(X_test)\n",
    "\n",
    "print(df_test_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f712c-2895-4962-ad06-85da032fd597",
   "metadata": {},
   "source": [
    "# Task 2) Experiments for both rating prediction and ranking tasks, and conducting offline evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eee40a",
   "metadata": {},
   "source": [
    "### Rating Prediction Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56177635-1c91-4ca6-845e-5ae874726b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - RMSE: 1.0946\n",
      "Epoch 2/10 - RMSE: 1.0560\n",
      "Epoch 3/10 - RMSE: 1.0304\n",
      "Epoch 4/10 - RMSE: 1.0123\n",
      "Epoch 5/10 - RMSE: 0.9987\n",
      "Epoch 6/10 - RMSE: 0.9882\n",
      "Epoch 7/10 - RMSE: 0.9797\n",
      "Epoch 8/10 - RMSE: 0.9728\n",
      "Epoch 9/10 - RMSE: 0.9670\n",
      "Epoch 10/10 - RMSE: 0.9620\n",
      "(factors=20, lr=0.001, reg=0.001, ep=10) - RMSE=0.9999497735848447\n",
      "Epoch 1/20 - RMSE: 1.0950\n",
      "Epoch 2/20 - RMSE: 1.0564\n",
      "Epoch 3/20 - RMSE: 1.0308\n",
      "Epoch 4/20 - RMSE: 1.0126\n",
      "Epoch 5/20 - RMSE: 0.9991\n",
      "Epoch 6/20 - RMSE: 0.9885\n",
      "Epoch 7/20 - RMSE: 0.9800\n",
      "Epoch 8/20 - RMSE: 0.9731\n",
      "Epoch 9/20 - RMSE: 0.9673\n",
      "Epoch 10/20 - RMSE: 0.9623\n",
      "Epoch 11/20 - RMSE: 0.9580\n",
      "Epoch 12/20 - RMSE: 0.9542\n",
      "Epoch 13/20 - RMSE: 0.9508\n",
      "Epoch 14/20 - RMSE: 0.9477\n",
      "Epoch 15/20 - RMSE: 0.9450\n",
      "Epoch 16/20 - RMSE: 0.9424\n",
      "Epoch 17/20 - RMSE: 0.9401\n",
      "Epoch 18/20 - RMSE: 0.9380\n",
      "Epoch 19/20 - RMSE: 0.9359\n",
      "Epoch 20/20 - RMSE: 0.9341\n",
      "(factors=20, lr=0.001, reg=0.001, ep=20) - RMSE=0.9999497735848447\n",
      "Epoch 1/30 - RMSE: 1.0947\n",
      "Epoch 2/30 - RMSE: 1.0561\n",
      "Epoch 3/30 - RMSE: 1.0306\n",
      "Epoch 4/30 - RMSE: 1.0124\n",
      "Epoch 5/30 - RMSE: 0.9989\n",
      "Epoch 6/30 - RMSE: 0.9884\n",
      "Epoch 7/30 - RMSE: 0.9799\n",
      "Epoch 8/30 - RMSE: 0.9730\n",
      "Epoch 9/30 - RMSE: 0.9672\n",
      "Epoch 10/30 - RMSE: 0.9622\n",
      "Epoch 11/30 - RMSE: 0.9579\n",
      "Epoch 12/30 - RMSE: 0.9541\n",
      "Epoch 13/30 - RMSE: 0.9507\n",
      "Epoch 14/30 - RMSE: 0.9477\n",
      "Epoch 15/30 - RMSE: 0.9449\n",
      "Epoch 16/30 - RMSE: 0.9424\n",
      "Epoch 17/30 - RMSE: 0.9401\n",
      "Epoch 18/30 - RMSE: 0.9379\n",
      "Epoch 19/30 - RMSE: 0.9359\n",
      "Epoch 20/30 - RMSE: 0.9341\n",
      "Epoch 21/30 - RMSE: 0.9323\n",
      "Epoch 22/30 - RMSE: 0.9306\n",
      "Epoch 23/30 - RMSE: 0.9291\n",
      "Epoch 24/30 - RMSE: 0.9276\n",
      "Epoch 25/30 - RMSE: 0.9261\n",
      "Epoch 26/30 - RMSE: 0.9248\n",
      "Epoch 27/30 - RMSE: 0.9235\n",
      "Epoch 28/30 - RMSE: 0.9222\n",
      "Epoch 29/30 - RMSE: 0.9210\n",
      "Epoch 30/30 - RMSE: 0.9198\n",
      "(factors=20, lr=0.001, reg=0.001, ep=30) - RMSE=0.9999497735848447\n",
      "Epoch 1/40 - RMSE: 1.0949\n",
      "Epoch 2/40 - RMSE: 1.0562\n",
      "Epoch 3/40 - RMSE: 1.0306\n",
      "Epoch 4/40 - RMSE: 1.0125\n",
      "Epoch 5/40 - RMSE: 0.9989\n",
      "Epoch 6/40 - RMSE: 0.9883\n",
      "Epoch 7/40 - RMSE: 0.9799\n",
      "Epoch 8/40 - RMSE: 0.9729\n",
      "Epoch 9/40 - RMSE: 0.9671\n",
      "Epoch 10/40 - RMSE: 0.9621\n",
      "Epoch 11/40 - RMSE: 0.9578\n",
      "Epoch 12/40 - RMSE: 0.9540\n",
      "Epoch 13/40 - RMSE: 0.9506\n",
      "Epoch 14/40 - RMSE: 0.9475\n",
      "Epoch 15/40 - RMSE: 0.9448\n",
      "Epoch 16/40 - RMSE: 0.9422\n",
      "Epoch 17/40 - RMSE: 0.9399\n",
      "Epoch 18/40 - RMSE: 0.9377\n",
      "Epoch 19/40 - RMSE: 0.9357\n",
      "Epoch 20/40 - RMSE: 0.9339\n",
      "Epoch 21/40 - RMSE: 0.9321\n",
      "Epoch 22/40 - RMSE: 0.9304\n",
      "Epoch 23/40 - RMSE: 0.9288\n",
      "Epoch 24/40 - RMSE: 0.9273\n",
      "Epoch 25/40 - RMSE: 0.9259\n",
      "Epoch 26/40 - RMSE: 0.9245\n",
      "Epoch 27/40 - RMSE: 0.9232\n",
      "Epoch 28/40 - RMSE: 0.9219\n",
      "Epoch 29/40 - RMSE: 0.9207\n",
      "Epoch 30/40 - RMSE: 0.9195\n",
      "Epoch 31/40 - RMSE: 0.9183\n",
      "Epoch 32/40 - RMSE: 0.9172\n",
      "Epoch 33/40 - RMSE: 0.9161\n",
      "Epoch 34/40 - RMSE: 0.9150\n",
      "Epoch 35/40 - RMSE: 0.9139\n",
      "Epoch 36/40 - RMSE: 0.9129\n",
      "Epoch 37/40 - RMSE: 0.9119\n",
      "Epoch 38/40 - RMSE: 0.9109\n",
      "Epoch 39/40 - RMSE: 0.9098\n",
      "Epoch 40/40 - RMSE: 0.9089\n",
      "(factors=20, lr=0.001, reg=0.001, ep=40) - RMSE=0.9999497735848447\n",
      "Epoch 1/50 - RMSE: 1.0949\n",
      "Epoch 2/50 - RMSE: 1.0563\n",
      "Epoch 3/50 - RMSE: 1.0307\n",
      "Epoch 4/50 - RMSE: 1.0126\n",
      "Epoch 5/50 - RMSE: 0.9990\n",
      "Epoch 6/50 - RMSE: 0.9884\n",
      "Epoch 7/50 - RMSE: 0.9800\n",
      "Epoch 8/50 - RMSE: 0.9730\n",
      "Epoch 9/50 - RMSE: 0.9672\n",
      "Epoch 10/50 - RMSE: 0.9622\n",
      "Epoch 11/50 - RMSE: 0.9579\n",
      "Epoch 12/50 - RMSE: 0.9541\n",
      "Epoch 13/50 - RMSE: 0.9507\n",
      "Epoch 14/50 - RMSE: 0.9476\n",
      "Epoch 15/50 - RMSE: 0.9448\n",
      "Epoch 16/50 - RMSE: 0.9423\n",
      "Epoch 17/50 - RMSE: 0.9400\n",
      "Epoch 18/50 - RMSE: 0.9378\n",
      "Epoch 19/50 - RMSE: 0.9358\n",
      "Epoch 20/50 - RMSE: 0.9339\n",
      "Epoch 21/50 - RMSE: 0.9322\n",
      "Epoch 22/50 - RMSE: 0.9305\n",
      "Epoch 23/50 - RMSE: 0.9289\n",
      "Epoch 24/50 - RMSE: 0.9274\n",
      "Epoch 25/50 - RMSE: 0.9259\n",
      "Epoch 26/50 - RMSE: 0.9246\n",
      "Epoch 27/50 - RMSE: 0.9232\n",
      "Epoch 28/50 - RMSE: 0.9219\n",
      "Epoch 29/50 - RMSE: 0.9207\n",
      "Epoch 30/50 - RMSE: 0.9195\n",
      "Epoch 31/50 - RMSE: 0.9183\n",
      "Epoch 32/50 - RMSE: 0.9172\n",
      "Epoch 33/50 - RMSE: 0.9161\n",
      "Epoch 34/50 - RMSE: 0.9150\n",
      "Epoch 35/50 - RMSE: 0.9139\n",
      "Epoch 36/50 - RMSE: 0.9128\n",
      "Epoch 37/50 - RMSE: 0.9118\n",
      "Epoch 38/50 - RMSE: 0.9108\n",
      "Epoch 39/50 - RMSE: 0.9097\n",
      "Epoch 40/50 - RMSE: 0.9087\n",
      "Epoch 41/50 - RMSE: 0.9077\n",
      "Epoch 42/50 - RMSE: 0.9067\n",
      "Epoch 43/50 - RMSE: 0.9057\n",
      "Epoch 44/50 - RMSE: 0.9047\n",
      "Epoch 45/50 - RMSE: 0.9037\n",
      "Epoch 46/50 - RMSE: 0.9027\n",
      "Epoch 47/50 - RMSE: 0.9016\n",
      "Epoch 48/50 - RMSE: 0.9006\n",
      "Epoch 49/50 - RMSE: 0.8996\n",
      "Epoch 50/50 - RMSE: 0.8986\n",
      "(factors=20, lr=0.001, reg=0.001, ep=50) - RMSE=0.9999497735848447\n",
      "Epoch 1/10 - RMSE: 1.0948\n",
      "Epoch 2/10 - RMSE: 1.0562\n",
      "Epoch 3/10 - RMSE: 1.0307\n",
      "Epoch 4/10 - RMSE: 1.0126\n",
      "Epoch 5/10 - RMSE: 0.9991\n",
      "Epoch 6/10 - RMSE: 0.9886\n",
      "Epoch 7/10 - RMSE: 0.9801\n",
      "Epoch 8/10 - RMSE: 0.9732\n",
      "Epoch 9/10 - RMSE: 0.9674\n",
      "Epoch 10/10 - RMSE: 0.9624\n",
      "(factors=20, lr=0.001, reg=0.01, ep=10) - RMSE=0.9999497735848447\n",
      "Epoch 1/20 - RMSE: 1.0947\n",
      "Epoch 2/20 - RMSE: 1.0562\n",
      "Epoch 3/20 - RMSE: 1.0307\n",
      "Epoch 4/20 - RMSE: 1.0126\n",
      "Epoch 5/20 - RMSE: 0.9991\n",
      "Epoch 6/20 - RMSE: 0.9886\n",
      "Epoch 7/20 - RMSE: 0.9801\n",
      "Epoch 8/20 - RMSE: 0.9732\n",
      "Epoch 9/20 - RMSE: 0.9674\n",
      "Epoch 10/20 - RMSE: 0.9624\n",
      "Epoch 11/20 - RMSE: 0.9581\n",
      "Epoch 12/20 - RMSE: 0.9543\n",
      "Epoch 13/20 - RMSE: 0.9510\n",
      "Epoch 14/20 - RMSE: 0.9480\n",
      "Epoch 15/20 - RMSE: 0.9452\n",
      "Epoch 16/20 - RMSE: 0.9427\n",
      "Epoch 17/20 - RMSE: 0.9404\n",
      "Epoch 18/20 - RMSE: 0.9383\n",
      "Epoch 19/20 - RMSE: 0.9363\n",
      "Epoch 20/20 - RMSE: 0.9344\n",
      "(factors=20, lr=0.001, reg=0.01, ep=20) - RMSE=0.9999497735848447\n",
      "Epoch 1/30 - RMSE: 1.0946\n",
      "Epoch 2/30 - RMSE: 1.0561\n",
      "Epoch 3/30 - RMSE: 1.0306\n",
      "Epoch 4/30 - RMSE: 1.0125\n",
      "Epoch 5/30 - RMSE: 0.9989\n",
      "Epoch 6/30 - RMSE: 0.9884\n",
      "Epoch 7/30 - RMSE: 0.9800\n",
      "Epoch 8/30 - RMSE: 0.9731\n",
      "Epoch 9/30 - RMSE: 0.9672\n",
      "Epoch 10/30 - RMSE: 0.9623\n",
      "Epoch 11/30 - RMSE: 0.9580\n",
      "Epoch 12/30 - RMSE: 0.9542\n",
      "Epoch 13/30 - RMSE: 0.9508\n",
      "Epoch 14/30 - RMSE: 0.9477\n",
      "Epoch 15/30 - RMSE: 0.9450\n",
      "Epoch 16/30 - RMSE: 0.9425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19032\\3889802616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m                     \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 )\n\u001b[1;32m--> 102\u001b[1;33m                 \u001b[0mmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf_rating_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19032\\377930648.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, ratings, verbose)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                 \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mpred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_mean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_bias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_bias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "def MSE(actual_rating, pred_rating):\n",
    "    \"\"\"\n",
    "    Calculate the mean squared error (MSE) between actual ratings and predicted ratings where both arguments are arrays.\n",
    "    \"\"\"\n",
    "    result = np.mean((actual_rating - pred_rating) ** 2)\n",
    "\n",
    "    return result\n",
    "\n",
    "def RMSE(actual_rating, pred_rating):\n",
    "    \"\"\"\n",
    "    Calculate the root mean squared error (RMSE) between actual ratings and predicted ratings where both arguments are arrays.\n",
    "    \"\"\"\n",
    "    result = np.sqrt(MSE(actual_rating, pred_rating))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_rating_prediction(test_data):\n",
    "    \"\"\"\n",
    "    Evaluates the models by measuring the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    rmse_cb = RMSE(test_data['rating'], test_data['CB_pred'])\n",
    "    rmse_user = RMSE(test_data['rating'], test_data['UserKNN_pred'])\n",
    "    rmse_item = RMSE(test_data['rating'], test_data['ItemKNN_pred'])\n",
    "    rmse_mf = RMSE(test_data['rating'], test_data['MF_pred'])\n",
    "\n",
    "    print(\"Model evaluations in terms of RMSE:\")\n",
    "    print(\"Content-based: \", rmse_cb)\n",
    "    print(\"User-based: \", rmse_user)\n",
    "    print(\"Item-based: \", rmse_item)\n",
    "    print(\"Matrix factorization: \", rmse_mf)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "# Content-based Model\n",
    "content_types = ['title_genres', 'description', 'full']\n",
    "aggregation_methods = ['avg', 'weighted_avg', 'avg_pos']\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_cb_setting = {}\n",
    "\n",
    "for ctype in content_types:\n",
    "    for method in aggregation_methods:\n",
    "        predictions = content_based_rating_prediction(train_data, test_data, ctype, method)\n",
    "        rmse_cb = RMSE(predictions['rating'], predictions[f'CB_pred_{ctype}_{method}'])\n",
    "        print(f\"({ctype}, {method}) - RMSE={rmse_cb}\")\n",
    "        \n",
    "        if rmse_cb < best_rmse:\n",
    "            best_rmse = rmse_cb\n",
    "            best_cb_setting = {'content_type': ctype, 'method': method}\n",
    "\n",
    "print(\"\\nBest content-based RMSE:\", best_rmse)\n",
    "print(\"Best setting:\", best_cb_setting, \"\\n\")\n",
    "\n",
    "# User-based KNN Model\n",
    "best_rmse = float('inf')\n",
    "best_user_k = None\n",
    "\n",
    "for k in [5, 10, 20, 30, 40, 50]:\n",
    "    predictions = user_based_rating_prediction(train_data, user_similarity_matrix, test_data, k)\n",
    "    rmse_user = RMSE(predictions['rating'], predictions[f'UserKNN_pred_{k}'])\n",
    "    \n",
    "    print(f\"k={k} - RMSE={rmse_user}\")\n",
    "    \n",
    "    if rmse_user < best_rmse:\n",
    "        best_rmse = rmse_user\n",
    "        best_user_k = k\n",
    "\n",
    "print(f\"\\nBest user-based KNN RMSE: {best_rmse} at k={best_user_k}\\n\")\n",
    "\n",
    "# Item-based KNN Model\n",
    "best_rmse = float('inf')\n",
    "best_item_k = None\n",
    "\n",
    "for k in [5, 10, 20, 25, 30, 40, 50, 100]:\n",
    "    predictions = item_based_rating_prediction(train_data, item_similarity_matrix, test_data, k)\n",
    "    rmse_item = RMSE(predictions['rating'], predictions[f'ItemKNN_pred_{k}'])\n",
    "    \n",
    "    print(f\"k={k} - RMSE={rmse_item}\")\n",
    "    \n",
    "    if rmse_item < best_rmse:\n",
    "        best_rmse = rmse_item\n",
    "        best_item_k = k\n",
    "\n",
    "print(f\"\\nBest item-based KNN RMSE: {best_rmse} at k={best_item_k}\\n\")\n",
    "\n",
    "# Matrix Factorization\n",
    "best_rmse = float('inf')\n",
    "best_mf_setting = {}\n",
    "\n",
    "for factors in [20, 50, 100]:\n",
    "    for lr in [0.001, 0.005, 0.01, 0.2]:\n",
    "        for reg in [0.001, 0.01, 0.1]:\n",
    "            for ep in [10, 20, 30, 40, 50]:\n",
    "                mf = MatrixFactorizationSGD(\n",
    "                    n_factors=factors,\n",
    "                    learning_rate=lr,\n",
    "                    regularization=reg,\n",
    "                    n_epochs=ep\n",
    "                )\n",
    "                mf.fit(train_data)\n",
    "                predictions = mf_rating_prediction(mf, test_data)\n",
    "                \n",
    "                rmse_mf = RMSE(predictions['rating'], predictions['MF_pred'])\n",
    "                print(f\"(factors={factors}, lr={lr}, reg={reg}, ep={ep}) - RMSE={rmse_mf}\")\n",
    "                \n",
    "                if rmse_mf < best_rmse:\n",
    "                    best_rmse = rmse_mf\n",
    "                    best_mf_setting = {'n_factors': factors, 'lr': lr, 'reg': reg, 'ep': ep}\n",
    "\n",
    "print(\"\\nBest matrix factorization RMSE:\", best_rmse)\n",
    "print(\"Best setting:\", best_mf_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878099cc",
   "metadata": {},
   "source": [
    "### Ranking Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643533f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def Precision(ground_truth, rec_list):\n",
    "    # Implement a function that computes Precision across ground truth data and recommendation list generated for each user. \n",
    "    # Note that ground_truth and rec_list contain the list of items for all users, e.g., 2-dimensional arrays.\n",
    "\n",
    "    precisions = []\n",
    "    for gt, rec in zip(ground_truth, rec_list):\n",
    "        if len(rec) == 0:\n",
    "            precisions.append(0)\n",
    "        else:\n",
    "            hit_count = len(set(gt) & set(rec))\n",
    "            precisions.append(hit_count / len(rec))\n",
    "    result = np.mean(precisions)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def Recall(ground_truth, rec_list):\n",
    "    # Implement a function that computes Recall across ground truth data and recommendation list generated for each user. \n",
    "    # Note that ground_truth and rec_list contain the list of items for all users, e.g., 2-dimensional arrays.\n",
    "\n",
    "    recalls = []\n",
    "    for gt, rec in zip(ground_truth, rec_list):\n",
    "        if len(gt) == 0:\n",
    "            recalls.append(0)\n",
    "        else:\n",
    "            hit_count = len(set(gt) & set(rec))\n",
    "            recalls.append(hit_count / len(gt))\n",
    "    result = np.mean(recalls)\n",
    "\n",
    "    return result\n",
    "\n",
    "def NDCG(ground_truth, rec_list):\n",
    "    # Implement a function that computes NDCG across ground truth data and recommendation list generated for each user. \n",
    "    # Note that ground_truth and rec_list contain the list of items for all users, e.g., 2-dimensional arrays.\n",
    "\n",
    "    ndcgs = []\n",
    "    for gt, rec in zip(ground_truth, rec_list):\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(rec):\n",
    "            if item in gt:\n",
    "                dcg += 1.0 / np.log2(i + 2)  # log base 2, rank i+1\n",
    "        idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(gt), len(rec))))\n",
    "        ndcgs.append(dcg / idcg if idcg > 0 else 0)\n",
    "    result = np.mean(ndcgs)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3a3e5-adef-4144-b7ad-f5f55696972d",
   "metadata": {},
   "source": [
    "# Task 3) Implement baselines for both rating prediction and ranking tasks, and perform experiments with those baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5710b4-8bae-42f0-8990-41e7cec7433f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e10661af-16f3-41f1-b09a-0307f70c344f",
   "metadata": {},
   "source": [
    "# Task 4) Analysis of recommendation models. Analyzing the coefficients of hybrid model and the success of recommendation models for different users' groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23377855-cc19-4b06-a497-712a892ae3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9914f603-b893-471c-9622-4437855dd8fa",
   "metadata": {},
   "source": [
    "# Task 5) Evaluation of beyond accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a0e4b-adbe-4673-82f8-a75761666fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
